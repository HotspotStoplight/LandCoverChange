---
title: "Honiara MSA Urban Growth Modeling"
author: "Oliver Atwood, adapted from Ken Steif, 2019. Eds. Michael Fichman & Jenna Epstein"
date: "08/01/2023"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
    code_download: true
---

<style>
  .superbigimage{
      overflow-x:scroll;
      white-space: nowrap;
  }

  .superbigimage img{
     max-width: none;
  }


</style>



# 1. Introduction
Regional urban development is influenced by various stakeholders such as developers, real estate buyers, tenants, planners, and regulators, each pursuing their own objectives. To ensure economic productivity and sustainability, land use planning must consider both supply and demand-side insights.

This project focuses on the San Jose Metropolitan Statistical Area (MSA) as a case study, examining how a sprawling metropolitan area can balance economic growth with environmental sustainability by projecting land cover change. The project draws on data from sources such as the US Geological Survey (USGS), Census demographics, and Open Street Maps transportation infrastructure, as well as spatial lag features derived from land cover change, to better understand the relationship between development demand and environmentally sensitive land.

Through exploratory analysis, a geospatial predictive model is developed, trained on land cover changes from 2001-2019. This model is used to estimate development demand for the year 2040, while considering the impact on the environment and landscape fragmentation. The model's predictions are then used to guide new development in areas that support economic growth without compromising sustainability goals.

# 1.2. Setup

Below we load required libraries, mapTheme and plotTheme for consistent styling, and specify a palette of colors for visualizations
```{r setup}
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
```

```{r load_packages, message=FALSE, warning=FALSE, results = "hide"}
library(tigris)
library(tidyverse)
library(sf)
library(raster)
library(knitr)
library(kableExtra)
library(tidycensus)
library(tigris)
library(FNN)
library(caret)
library(yardstick)
library(pscl)
library(plotROC) 
library(ggrepel)
library(pROC)
library(grid)
library(gridExtra)
library(viridis)
library(igraph)
library(mapview)
library(exactextractr)
library(sp)
library(ggplot2)
library(dplyr)
library(terra)

# Capture the start time
start_time <- Sys.time()

plotTheme <- theme(
  plot.title =element_text(size=12),
  plot.subtitle = element_text(size=8),
  plot.caption = element_text(size = 6),
  axis.text.x = element_text(size = 10, angle = 45, hjust = 1),
  axis.text.y = element_text(size = 10),
  axis.title.y = element_text(size = 10),
  # Set the entire chart region to blank
  panel.background=element_blank(),
  plot.background=element_blank(),
  #panel.border=element_rect(colour="#F0F0F0"),
  # Format the grid
  panel.grid.major=element_line(colour="#D0D0D0",size=.75),
  axis.ticks=element_blank())

mapTheme <- theme(plot.title =element_text(size=12),
                  plot.subtitle = element_text(size=8),
                  plot.caption = element_text(size = 6),
                  axis.line=element_blank(),
                  axis.text.x=element_blank(),
                  axis.text.y=element_blank(),
                  axis.ticks=element_blank(),
                  axis.title.x=element_blank(),
                  axis.title.y=element_blank(),
                  panel.background=element_blank(),
                  panel.border=element_blank(),
                  panel.grid.major=element_line(colour = 'transparent'),
                  panel.grid.minor=element_blank(),
                  legend.direction = "vertical", 
                  legend.position = "right",
                  plot.margin = margin(1, 1, 1, 1, 'cm'),
                  legend.key.height = unit(1, "cm"), legend.key.width = unit(0.2, "cm"))

palette1 <- c("#cd0000","#0059c7")
palette2 <- c("#41b6c4","#253494")
palette4 <- c("#a1dab4","#41b6c4","#2c7fb8","#253494")
palette5 <- c("#ffffcc","#a1dab4","#41b6c4","#2c7fb8","#253494")
palette10 <- c("#f7fcf0","#e0f3db","#ccebc5","#a8ddb5","#7bccc4",
               "#4eb3d3","#2b8cbe","#0868ac","#084081","#f7fcf0")

```

We also include several helper functions. `quintilesBreaks` takes a dataframe and a column and outputs the quintiles breaks, helping shorten the `ggplot` calls below.

It takes longer to `ggplot` a polygon fishnet with `geom_sf` than it does to plot `geom_point`. To cut down on plotting time, the `xyC` (for ‘XY Coordinates’) takes a fishnet `sf` and converts it to a dataframe of grid cell centroid coordinates.

`rast` is a function allowing us to quickly plot raster values in `ggplot`.

```{r, warning = FALSE, message = FALSE}
#this function converts a column in to quintiles. It is used for mapping.
quintileBreaks <- function(df,variable) {
    as.character(quantile(df[[variable]],
                          c(.01,.2,.4,.6,.8),na.rm=T))
}

#This function can be used to convert a polygon sf to centroids xy coords.
xyC <- function(aPolygonSF) {
  as.data.frame(
    cbind(x=st_coordinates(st_centroid(aPolygonSF))[,1],
          y=st_coordinates(st_centroid(aPolygonSF))[,2]))
} 

#this function convert a raster to a data frame so it can be plotted in ggplot
rast <- function(inRaster) {
  data.frame(
    xyFromCell(inRaster, 1:ncell(inRaster)), 
    value = getValues(inRaster)) }
```

## Setting Parameters
```{r}
# coordinate_system <- 32756
# resolution <- 10000

coordinate_system <- 4326
# Target resolution in m
resolution <- 30
# Conversion to degrees
resolution <- (resolution/30)/3600

```


# 2. Data Wrangling & Feature Engineering

In this section a considerable amount of vector and raster data is wrangled together into a regression-ready dataset. The following datasets are used:

2.1 - 2.2: Land cover data: These data are sampled to a 30 by 30 meter fishnet.

2.3: Population data: downloaded from GHSL and joined to the fishnet by distributing population totals proportionally to each grid cell.

2.4: Highways and Roads

2.5: Slope values

2.6: Land cover change data

2.7: County polygons are downloaded using the `tigris` package.

2.8: Features are wrangled into a final dataset.

Data from each of these datasets is integrated into the vector fishnet to provide a comprehensive snapshot of the development process and context in and around San Jose between 2013 and 2023.
<br>

## 2.1. Land Cover Change Data

We aim to forecast the dependent variable of land cover change between 2013 and 2019. In this section, we load the land cover raster data, reclassify it, and integrate it with a vector fishnet. This allows us to parameterize spatial relationships in a regression context.

The table below shows descriptions of each categorical land cover type in the Sentinel Derivedland cover data. Below, we will reclassify these data into more useful categories.

| Class Value | Classification Description      |
| ----------- | ------------------------------- |
| 0           |   NoData                        |
| 1           |   Forest                        |
| 2           |   Grassland/Cropland            |
| 3           |   Urban                         |
| 4           |   Water                         |
| 5           |   Wetland/Mangroves             |
 
Several layers have been provided for this analysis: 

- We create `SJ__Grid` - this is a fishnet covering the extent of our study area 

- `lc_change` is a raster of land cover change - where there were conversions between one land cover and another on the time frame 2001-2019. We plot the raster using `ggplot` and the `rast` function specified above.

Note that `lc_change` is projected as `WGS 1984 PDC Mercator` and is spatially referenced as `EPSG:3832`. It has also been clipped in ArcGIS to the boundary of our study area. 


```{r raster pre-processing}
# Read the rasters
cropbox <- st_read("https://raw.githubusercontent.com/HotspotStoplight/HotspotStoplight/main/CropBoxes/CR_Crop6.geojson")
lc_2013 = raster('https://raw.githubusercontent.com/HotspotStoplight/HotspotStoplight/main/UrbanExpansion/data/Land%20Cover%20Classification%20for%20San%20Jose%20CR%2C%202013-2014%2C%202017-2018%2C%202022-2023/Landcover_Landsat8_2013_2014_CostaRica_SanJose.tif')
lc_2023 = raster('https://raw.githubusercontent.com/HotspotStoplight/HotspotStoplight/main/UrbanExpansion/data/Land%20Cover%20Classification%20for%20San%20Jose%20CR%2C%202013-2014%2C%202017-2018%2C%202022-2023/Landcover_Landsat9_2022_2023_CostaRica_SanJose.tif')
# prox_road = raster('https://raw.githubusercontent.com/HotspotStoplight/HotspotStoplight/main/UrbanExpansion/data/roads_proximity.tif')
# prox_highway = raster('https://raw.githubusercontent.com/HotspotStoplight/HotspotStoplight/main/UrbanExpansion/data/highway_proximity.tif')
pop2010 = raster('/Users/oliveratwood/Documents/GitHub/HotspotStoplight/UrbanExpansion/data/Pop_2010_Crop4.tif')
pop2020 = raster('/Users/oliveratwood/Documents/GitHub/HotspotStoplight/UrbanExpansion/data/Pop_2020_Crop4.tif')
slope = raster('/Users/oliveratwood/Documents/GitHub/HotspotStoplight/UrbanExpansion/data/Slope.tif')
wdpa = raster('/Users/oliveratwood/Documents/GitHub/HotspotStoplight/UrbanExpansion/data/wdpa.tif')


# Project the rasters
# Check if CRS of prox_road is not the same as coordinate_system
# prox_road <- projectRaster(prox_road, crs = coordinate_system, method = "bilinear")
# prox_highway <- projectRaster(prox_highway, crs = coordinate_system, method = "bilinear")
pop2010 <- projectRaster(pop2010, crs = coordinate_system, method = "bilinear")
pop2020 <- projectRaster(pop2020, crs = coordinate_system, method = "bilinear")
slope <- projectRaster(slope, crs = coordinate_system, method = "bilinear")
wdpa <- projectRaster(wdpa, crs = coordinate_system, method = "ngb")

# Clip the rasters with the polygon
lc_2013 <- crop(lc_2013, cropbox)
lc_2023 <- crop(lc_2023, cropbox)
# prox_road <- crop(prox_road, cropbox)
# prox_highway <- crop(prox_highway, cropbox)
pop2010 <- crop(pop2010, cropbox)
pop2020 <- crop(pop2020, cropbox)
slope <- crop(slope, cropbox)
wdpa <- crop(wdpa, cropbox)

plot(wdpa)

```

```{r}
# # Check alignment
# print(extent(lc_2013))
# print(extent(lc_2023))
# print(extent(pop2010))
# print(extent(pop2020))
# print(extent(slope))
# print(extent(wdpa))
# print(res(lc_2013))
# print(res(lc_2023))
# print(res(pop2010))
# print(res(pop2020))
# print(res(slope))
# print(res(wdpa))
# print(crs(lc_2013))
# print(crs(lc_2023))
# print(crs(pop2010))
# print(crs(pop2020))
# print(crs(slope))
# print(crs(wdpa))
# 
# # Align raster2 to raster1
# aligned_raster2 <- projectRaster(pop2010, lc_2013)
# 
# # Verify alignment
# print(extent(aligned_raster2))
# print(res(aligned_raster2))
# print(crs(aligned_raster2))
# 
# # Create a RasterStack
# raster_stack <- stack(raster1, aligned_raster2)
```

```{r make fishnet, fig.width=10}
# Get extents of the cropbox
cropbox_extent <- extent(cropbox)

# Create an empty raster with lc_2013's extent
r <- raster(cropbox_extent, res = resolution, crs = coordinate_system)

# Create the fishnet
SJ_Grid <- rasterToPolygons(r, fun = NULL, dissolve = FALSE)
SJ_Grid <- st_as_sf(SJ_Grid)
SJ_Grid <- st_set_crs(SJ_Grid, coordinate_system)

# Plot the fishnet
plot(SJ_Grid, main = "Fishnet Grid", col = 'blue', border = NA)

```

Now we calculate the pixels that changed to urban. We apply a name to the raster with `names`. This is done to make it faster to join raster to the fishnet below. 
```{r}
# Apply the conditions
condition_2013 <- lc_2013 != 3
condition_2023 <- lc_2023 == 3

# Combine the conditions to create a binary raster
lc_change <- condition_2013 & condition_2023

# Convert to binary values (1 for TRUE, 0 for FALSE)
lc_change <- as.integer(lc_change)

# Change 0 values to NA
lc_change[lc_change == 0] <- NA
names(lc_change) <- "lc_change"

# Plot the binary raster (optional)
plot(lc_change, main="Land Cover Change to Urban")

```

The code below converts the raster to an `sf` point layer and then joins the points to the fishnet with `aggregate`. Finally, the fishnet variable `lc_change` is created that is `1` where new development has occurred and `0` where it has not. This is our dependent variable and encoded as a factor.

```{r, warning = FALSE, message = FALSE}
changePoints <-
  rasterToPoints(lc_change) %>%
  as.data.frame() %>%
  st_as_sf(coords = c("x", "y"), crs = st_crs(SJ_Grid))

SJ_Grid <-
  aggregate(changePoints, SJ_Grid, sum)

# Plotting
ggplot() +
  geom_sf(data = SJ_Grid, aes(fill = lc_change), color = 'blue') +  # Use 'layer' for fill color
  # geom_sf(data = changePoints, color = 'red', size = 0.1) +
  theme_minimal() +
  labs(title = "Change Points and SJ_Grid") +
  scale_fill_viridis_c()

```

## 2.2. Land Cover in 2013

It is reasonable to hypothesize that the propensity of new development is a function of existing land cover categories. In this section we identify these other land cover categories from 2013 and integrate each with the fishnet.

```{r, warning = FALSE, message = FALSE}
plot(lc_2013)
```


The table below shows the approach taken to recode existing land cover codes into the categories used in our analysis. In the code block below new rasters are generated and `names` are applied. Naming ensures that when the raster is integrated with the fishnet, the column reflects the appropriate raster.


| Class Value | Classification Description      | New Classification
| ----------- | ------------------------------- | ---------------------
| 0           |   NoData                        | Forest
| 1           |   Forest                        | Forest
| 2           |   Grassland/Cropland            | Crop
| 3           |   Urban                         | Urban
| 4           |   Water                         | Water
| 5           |   Wetland/Mangroves             | Forest

# Joining Data to Fishnet

## Land Cover Data

## The Spatial Lag of Development

## Population Data

## Distance to Highways and Roads

## Slope

### Reclassify Land Cover
```{r, warning = FALSE, message = FALSE}
urban <- lc_2013 == 3
forest <- lc_2013 == 0 | lc_2013 == 1 | lc_2013 == 5
crop <- lc_2013 == 2
water <- lc_2013 == 4

names(urban) <- "urban"
names(forest) <- "forest"
names(crop) <- "crop"
names(water) <- "water"
```

# Spatial lag of development
```{r}

# # Create a copy of the urban raster layer
# prox_urban <- urban
# 
# # Replace all TRUE values (originally non-zero) with 1
# prox_urban[prox_urban == TRUE] <- 1
# 
# # Replace all FALSE values (originally zero) with NA
# prox_urban[prox_urban == FALSE] <- NA
# 
# # Compute proximity
# prox_urban <- distance(prox_urban)
# 
# names(prox_urban) <- "prox_urban"
plot(prox_urban)
# Convert urban raster to SpatRaster objects
prox_urban <- rast(urban)

# Convert to logical (TRUE for urban areas, FALSE otherwise)
prox_urban <- prox_urban != 0  

# Replace all TRUE values (originally non-zero) with 1
prox_urban <- ifel(prox_urban, 1, NA)

# Compute proximity
prox_urban_distance <- distance(prox_urban)

# Name the output raster layer
names(prox_urban_distance) <- "prox_urban"

```

Next, each raster is aggregated to the fishnet by way of a function called `aggregateRaster`. Here, the process used above to To do this, a function is created below that loops through a list of rasters, converts the _ith_ raster to points, filters only points that have value of `1` (ie. is the _ith_ land cover type), and then aggregates to the fishnet.

Here is the function.

```{r}
aggregateRaster <- function(inputRasterNames, theFishnet) {
  # Initialize an empty list to store results
  aggregatedResults <- list()

  # Process each raster
  for (rasterName in inputRasterNames) {
    # Load the raster from the global environment
    rasterLayer <- get(rasterName)

    # Convert raster to points
    thesePoints <- rasterToPoints(rasterLayer) %>%
      as.data.frame() %>%
      st_as_sf(coords = c("x", "y"), crs = st_crs(theFishnet)) %>%
      filter(.[[1]] == 1)

    # Aggregate to the fishnet
    thisFishnet <- aggregate(thesePoints, theFishnet, length) %>%
      mutate(!!sym(rasterName) := ifelse(is.na(.[[1]]), 0, 1))

    # Store the result
    aggregatedResults[[rasterName]] <- thisFishnet
  }

  # Combine all results
  combinedResults <- do.call(cbind, aggregatedResults)

  return(combinedResults)
}

```

```{r}
# Capture the start time
start_time <- Sys.time()
```

```{r}
# Usage
## Add "prox_urban",
theRasterNamesList <- c("urban", "forest", "crop", "water", "prox_road", "prox_highway", "pop2010", "slope", "wdpa")

aggregatedRasters <- aggregateRaster(theRasterNamesList, SJ_Grid)

```

```{r timer_end}
# Capture the end time
end_time <- Sys.time()

# Calculate and print the runtime
runtime <- end_time - start_time
print(paste("Total runtime:", runtime))
```

```{r}
SJ_Grid <- cbind(SJ_Grid, aggregatedRasters) %>% 
  rename(urban = urban.urban, forest = forest.forest, crop = crop.crop, water = water.water) %>% 
  select(-urban.geometry, -forest.geometry, -crop.geometry, -water.geometry)

```

The `theRasterList` of land cover types in 2001 is created and then fed into `aggregateRaster`. The result is converted to long form grid cell centroids and plot as small multiple maps.

Note that since our land cover data is at a different resolution than our fishnet, we have reassigned cells with more than one land cover value to just one based on a hierarchy. This method can introduce some degree of error, which is worse with lower-resolution fishnets. For our purposes, using a high-resolution fishnet, it performs just fine. Later iterations of this workflow will include a method for assigning the most common land cover type within each fishnet cell to that cell, which should reduce the degree of error that comes with lower-resolution fishnets.

Note also the inclusion of `st_cast` here which convert all geometries to `POLYGON`. If we create a frequency table of geometry types in `aggregatedRasters`, we will notice some and handful of `MULTIPOLYGONS`. Try `table(st_geometry_type(aggregatedRasters)`). These rogue multipolygons break the `xyC` function which is designed to find grid cell centroids. After all, there is no one centroid of several combined polygons. Thus `st_cast` ensures all geometries are just `POLYGON`.

```{r, warning = FALSE, message = FALSE}
# reassign cells with more than one lc value to just one based on hierarchy shown here
SJ_Grid <- SJ_Grid %>%
    mutate(lc_change = ifelse(lc_change >=1, 1, 0)) %>% 
    mutate(urban = ifelse(urban >= 1, 1, 0)) %>% 
    mutate(crop = ifelse(urban == 0 & crop >= 1, 1, 0)) %>%
    mutate(forest = ifelse(urban == 0 & crop == 0 & forest >= 1, 1, 0)) %>%
    mutate(water = ifelse(urban == 0 & crop == 0 & forest == 0 & water >= 1, 1, 0))

plot(SJ_Grid)
```

```{r timer_end}
# Capture the end time
end_time <- Sys.time()

# Calculate and print the runtime
runtime <- end_time - start_time
print(paste("Total runtime:", runtime))
```


!!!!!!!!!!!!!!!!!!!!Allocating Land Use claims at the national level???????????????????

# 3. Exploratory Analysis

In this section we explore the extent to which each feature is associated with development change. If the goal was to predict a continuous variable, scatterplots and correlation coefficients make this process straightforward and relatively easy to explain to a non-technical decision maker.

In this case however, the dependent variable is a binary outcome - either a grid cell was developed between 2001 and 2019 or it wasn’t. In this case, the relevant question is whether for a given feature, there is a statistically significant difference between areas that changed and areas that did not. These differences are explored in a set of plots below. For models with lots of features, these plots could be compliment by a series of difference in means statistical tests.

The below code block `select`s the highways and spatial lag features, converts each to long form and plots each as bar plots. Note that `geom_bar` calculates the `mean`. The mean distance_highways is significantly lower for the `New Development` category compared to the `No Change` category, it indicates that new developments tend to be closer to highways. On the other hand, the mean `lagDevelopment` is significantly lower for the `New Development` category compared to the `No Change` category, it may imply that new development is more likely to occur in areas that are near existing development.

```{r, warning = FALSE, message = FALSE}
dat %>%
  dplyr::select(distance_highways,lagDevelopment,lc_change) %>%
  gather(Variable, Value, -lc_change, -geometry) %>%
  ggplot(., aes(lc_change, Value, fill=lc_change)) + 
    geom_bar(position = "dodge", stat = "summary", fun.y = "mean") +
    facet_wrap(~Variable, scales = "free_y") +
    scale_fill_manual(values = palette2,
                      labels=c("No Change","New Development"),
                      name="") +
    labs(title="New Development as a Function of the Continuous Variables") +
    plotTheme 
```

Next, the same visualization is created for the population related variables. The higher mean values for `total_population`, `total_population2020`, and `pop_Change_00_20` in the `New Development` category suggest that development is more likely to occur in areas with higher populations and greater population growth. 

```{r, warning = FALSE, message = FALSE}
dat %>%
  dplyr::select(total_population,total_population2020,pop_Change_00_20,lc_change) %>%
  gather(Variable, Value, -lc_change, -geometry) %>%
  ggplot(., aes(lc_change, Value, fill=lc_change)) +
    geom_bar(position = "dodge", stat = "summary", fun.y = "mean") +
    facet_wrap(~Variable) +
    scale_fill_manual(values = palette2,
                      labels=c("No Change","New Development"),
                      name="") +
    labs(title="New Development as a Function of Factor Variables") +
    plotTheme
```

Next, a table of land cover conversion between 2001 and 2019 is created. The table suggests for instance, that 0.71% of The plots above suggest that the continuous variable (e.g., `distance_highways`, `lagDevelopment`, population related variables) has an association with the occurrence of new development.


Next, a table of land cover conversion between 2001 and 2019 is created. The table suggests for instance, that 0.77% of farmland regionally was converted to development between 2001 and 2019. 

```{r, warning = FALSE, message = FALSE}
dat %>%
  dplyr::select(lc_change:otherUndeveloped,developed) %>%
  gather(Land_Cover_Type, Value, -lc_change, -geometry) %>%
   st_set_geometry(NULL) %>%
     group_by(lc_change, Land_Cover_Type) %>%
     summarize(n = sum(as.numeric(Value))) %>%
     ungroup() %>%
    mutate(Conversion_Rate = paste0(round(100 * n/sum(n), 2), "%")) %>%
    filter(lc_change == 1) %>%
  dplyr::select(Land_Cover_Type,Conversion_Rate) %>%
  kable() %>% kable_styling(full_width = F)
```


# 4. Predicting for 2019

In this section, six separate logistic regression models are estimated to predict development change between 2001 and 2019 - with each subsequent model more sophisticated then the last. To do so, the data is split into 50% training/test sets. Models are estimated on the training set.

For brevity, a less sophisticated approach to describing the accuracy and generalizability of predictions for each model is taken here, judging each by the McFadden or “Psuedo” R Squared statistic on the test set. The model with the greatest goodness of fit is then used for the purposes of prediction.

## 4.1. Modeling

First, `dat` is split into training and test sets. Note how imbalanced the panel is with `table(datTrain$lc_change1)`.

```{r, warning = FALSE, message = FALSE}
set.seed(3456)
trainIndex <- 
  createDataPartition(dat$developed, p = .50,
                                  list = FALSE,
                                  times = 1)
datTrain <- dat[ trainIndex,]
datTest  <- dat[-trainIndex,]

nrow(dat)
```

Next six separate `glm` models are estimated adding new variables for each. Figure 4.1 shows the Psuedo R-Squared associated with each model.

`Model1` includes only the 2001 land cover types. `Model2` adds the `lagDevelopment`. Models 3, 4 and 5 attempt three different approaches for modeling demographic changes, infrastructure and slope; `Model3` uses 2000 population and distance to highway, `Model4` adds slope to Model3, and `Model5` adds population change to Model4. `Model6` adds demographic features to Model5.

```{r, warning = FALSE, message = FALSE}
Model1 <- glm(lc_change ~ wetlands + forest  + farm + otherUndeveloped, 
              family="binomial"(link="logit"), data = datTrain)

Model2 <- glm(lc_change ~ wetlands + forest  + farm + otherUndeveloped + lagDevelopment, 
              family="binomial"(link="logit"), data = datTrain)
              
Model3 <- glm(lc_change ~ wetlands + forest  + farm + otherUndeveloped + lagDevelopment + total_population +
                 distance_highways, 
              family="binomial"(link="logit"), data = datTrain)  

Model4 <- glm(lc_change ~ wetlands + forest  + farm + otherUndeveloped + lagDevelopment + total_population +
                 distance_highways + slope, 
                family="binomial"(link="logit"), data = datTrain)  

Model5 <- glm(lc_change ~ wetlands + forest  + farm + otherUndeveloped + lagDevelopment + total_population +
                 distance_highways + slope + pop_Change_00_20 + total_population2020,
                family="binomial"(link="logit"), data = datTrain)               

Model6 <- glm(lc_change ~ wetlands + forest  + farm + otherUndeveloped + lagDevelopment +
                 distance_highways + slope + pop_Change_00_20
                 + total_housing_units  + total_white,
                family="binomial"(link="logit"), data = datTrain)
```

Below codes create a data frame of psudeo R Squares for each model and plotting them for comparison. This approach loops through the models retrieving the goodness of fit for each. `Model6` is the final model employed for prediction.

```{r, warning = FALSE, message = FALSE}
modelList <- paste0("Model", 1:6)
map_dfc(modelList, function(x)pR2(get(x)))[4,] %>%
  setNames(paste0("Model",1:6)) %>%
  gather(Model,McFadden) %>%
  ggplot(aes(Model,McFadden)) +
    geom_bar(stat="identity") +
    labs(title= "McFadden R-Squared by Model") +
    plotTheme
```

Next, a data frame is created that includes columns for the observed development change, `lc_change`, and one that includes predicted probabilities for `Model6`. This data frame is then used as an input to a density plot visualizing the distribution of predicted probabilities by observed class. Only a small number of predicted probabilities are greater than or equal to 50% `(nrow(filter(testSetProbs, probs >= .50)) / nrow(datTest))`. This makes good sense, given how rare of an event development is in our dataset. Ultimately, in order to judge our model with a confusion matrix, a smaller development classification threshold must be employed.

```{r, warning = FALSE, message = FALSE}
testSetProbs <- 
  data.frame(class = datTest$lc_change,
             probs = predict(Model6, datTest, type="response")) 
  
ggplot(testSetProbs, aes(probs)) +
  geom_density(aes(fill=class), alpha=0.5) +
  scale_fill_manual(values = palette1,
                    labels=c("No Change","New Development")) +
  labs(title = "Histogram of test set predicted probabilities",
       x="Predicted Probabilities",y="Density") +
  plotTheme
```

## 4.2. Accuracy

Now to pick a predicted probability threshold to classify an area as having new development. *Sensitivity* or the True Positive rate is the proportion of actual positives (1’s) that were predicted to be positive. For example, the Sensitivity in our model is the rate of developed areas actually predicted as such. *Specificity* or True Negative Rate is the proportion of actual negatives (0’s) that were predicted to be negatives. For example, the Specificity in our model is the rate of No Change areas that were correctly predicted as No change.

There are some clear trade-offs between Sensitivity and Specificity in our model that deserve some exploration. To illustrate, two different thresholds of 13% and 30% are explored. Predicted classes for both thresholds are generated and instead of using the `confusionMatrix` function from `caret` as we have in the past, here confusion matrix metrics are derived from the `yardstick` package. This allows us to `group_by` the threshold and `summarize` the metrics of interest.

The `options` call below is required to tell `yardstick` that the positive factor class in `testSetProbs` is `1`. Without it, yardstick will by default see the first factor level as `0` and flip the confusion metrics around.

```{r, warning = FALSE, message = FALSE}
options(yardstick.event_first = FALSE)

testSetProbs <- 
  testSetProbs %>% 
  mutate(predClass_05 = as.factor(ifelse(testSetProbs$probs >= 0.05 ,1,0)),
         predClass_20 = as.factor(ifelse(testSetProbs$probs >= 0.2 ,1,0))) 

testSetProbs %>%
  dplyr::select(-probs) %>%
  gather(Variable, Value, -class) %>%
  group_by(Variable) %>%
  summarize(Sensitivity = round(yardstick::sens_vec(class,factor(Value)),2),
            Specificity = round(yardstick::spec_vec(class,factor(Value)),2),
            Accuracy = round(yardstick::accuracy_vec(class,factor(Value)),2)) %>% 
  kable() %>%
  kable_styling(full_width = F)
```

The 13% threshold correctly predicts a higher number of new development areas (Sensitivity), but incorrectly predicts a lower number of no change areas (Specificity). As there are far more no change areas in the data, this is reflected in a lower overall accuracy. Conversely, the 30% threshold has a lower Sensitivity rate and but a far higher Specificity rate. Again, because of the dataset is majority no change areas, this leads to a far higher Accuracy rate.

Given the use case, and the spatial distribution of land cover change, it may be more useful to have a model that predicts generally where new development occurs rather than one that predicts precisely where. As illustrated below, the 20% threshold provides this outcome. These trade-offs can be visualized in the plot below. Here the model is used to predict for the entire `dat` dataset. 20% threshold looks more reasonable given the distribution of observed development change.

```{r, warning = FALSE, message = FALSE}
predsForMap <-         
  dat %>%
    mutate(probs = predict(Model6, dat, type="response") ,
           Threshold_5_Pct = as.factor(ifelse(probs >= 0.05 ,1,0)),
           Threshold_20_Pct =  as.factor(ifelse(probs >= 0.20 ,1,0))) %>%
    dplyr::select(lc_change,Threshold_5_Pct,Threshold_20_Pct) %>%
    gather(Variable,Value, -geometry) %>%
    st_cast("POLYGON")
```


<div class="superbigimage">
```{r, warning = FALSE, message= FALSE, fig.height = 6, fig.width= 8}
ggplot() +
  geom_point(data=predsForMap, aes(x=xyC(predsForMap)[,1], y=xyC(predsForMap)[,2], colour=Value)) +
  facet_wrap(~Variable) +
  scale_colour_manual(values = palette2, labels=c("No Change","New Development"),
                      name="") +
  labs(title="Development Predictions - Low Threshold") + 
  mapTheme
```
</div>

To provide a bit more insight, the code block below produces both true positives (Sensitivity) and true negatives (Specificity) for each grid cell by threshold type.

```{r, warning = FALSE, message = FALSE}
ConfusionMatrix.metrics <-
  dat %>%
    mutate(probs = predict(Model3, dat, type="response") ,
           Threshold_5_Pct = as.factor(ifelse(probs >= 0.05 ,1,0)),
           Threshold_20_Pct =  as.factor(ifelse(probs >= 0.20 ,1,0))) %>%
    mutate(TrueP_05 = ifelse(lc_change  == 1 & Threshold_5_Pct == 1, 1,0),
           TrueN_05 = ifelse(lc_change  == 0 & Threshold_5_Pct == 0, 1,0),
           TrueP_20 = ifelse(lc_change  == 1 & Threshold_20_Pct == 1, 1,0),
           TrueN_20 = ifelse(lc_change  == 0 & Threshold_20_Pct == 0, 1,0)) %>%
    dplyr::select(., starts_with("True")) %>%
    gather(Variable, Value, -geometry) %>%
    st_cast("POLYGON") 
```

<div class="superbigimage">
```{r, warning = FALSE, message = FALSE, fig.height= 8, fig.width= 8 }
ggplot(data=ConfusionMatrix.metrics) +
  geom_point(aes(x=xyC(ConfusionMatrix.metrics)[,1], 
                 y=xyC(ConfusionMatrix.metrics)[,2], colour = as.factor(Value))) +
  facet_wrap(~Variable) +
  scale_colour_manual(values = palette2, labels=c("Correct","Incorrect"),
                       name="") +
  labs(title="Development Predictions - Low Threshold") + mapTheme
```
</div>


# 5. Predicting Land Cover Demand for 2040

## 5.1. Update Population Change and Lag Development values

At this point, a simple but useful model has been trained to predict urban development between 2001 and 2019 as a function of baseline features from 2001 including land cover, built environment and population. Next, we are going to update our features to reflect a 2019 baseline. Having done so, predictions from our new model would then be for 2040.

For brevity, we only update two features in our model for now. First, population change (`pop_change`) is updated using county level population projections visualized in the plot below. The second is `lagDevelopment`, which describes how predicted new development relates in space to old development.

Once the features are updated, 2040 predictions are estimated and mapped.

Below, `lagDevelopment` is mutated to describe average distance to 2019 development. Note that the field name, `lagDevelopment` is unchanged (ie. not updated to `lagDevelopment_2019`). This is done purposefully as model6 has a regression coefficient called `lagDevelopment`. If this variable wasn’t present in our updated data frame then the `predict` command would fail.

```{r, warning = FALSE, message = FALSE}
dat <-
  dat %>%
  mutate(lagDevelopment = nn_function(xyC(.), xyC(filter(.,developed19lag == 2)),2))
```

Now to update population change. A new data frame, `countyPopulation_2040` is created which includes 2020 population counts and 2040 projections for each county in the study area. Population is plotted by year and by county. 

```{r, warning = FALSE, message = FALSE}
countyPopulation_2040 <- 
  data.frame(
   NAME = 
     c("Albemarle","Charlottesville"),
   county_projection_2040 = 
     c(138523,48939)) %>%
   left_join(
     dat %>%
       st_set_geometry(NULL) %>%
       group_by(NAME) %>%
       summarize(county_population_2020 = round(sum(total_population2020))))

countyPopulation_2040 %>%
  gather(Variable,Value, -NAME) %>%
  ggplot(aes(reorder(NAME,-Value),Value)) +
  geom_bar(aes(fill=Variable), stat = "identity", position = "dodge") +
  scale_fill_manual(values = palette2,
                    labels=c("2040","2020"),
                    name="Population") +
  labs(title="Population Change by County: 2020 - 2040",
       x="County", y="Population") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  plotTheme
```

## 5.2. Predicting Development Demand

Next, the `countyPopulation_2040` table is joined to `dat` and `pop_change` in order to ‘distribute’ the new population across the study area. To do so, the the allocation of new population is weighted by a grid cell’s existing population (`pop_2040.infill`). 2020 population is subtracted from this figure to get `pop_Change`. Finally, `Model6` is used to predict for 2040 given the updated population change and lag development features.

The map of predicted probabilities that results is best thought of as a measure of predicted development demand in 2040.

```{r, warning = FALSE, message = FALSE}
dat_infill <-
  dat %>%
  #calculate population change
    left_join(countyPopulation_2040) %>%
    mutate(proportion_of_county_pop = total_population2020 / county_population_2020,
           pop_2040.infill = proportion_of_county_pop * county_projection_2040,
           pop_Change = round(pop_2040.infill - total_population2020),2) %>%
    dplyr::select(-county_projection_2040, -county_population_2020, 
                  -proportion_of_county_pop, -pop_2040.infill) %>%
  #add values for 2020 baseline (forest, farm, etc.)
  
  #predict for 2040
    mutate(predict_2040.infill = predict(Model3,. , type="response"))

# dat_infill <- dat_infill %>% 
#   mutate(predict_2040.infill2 =ifelse(predict_2040.infill < 0.01 | predict_2040.infill > 1, 0, predict_2040.infill))

dat_infill %>%
  ggplot() +  
  geom_sf(aes(fill = predict_2040.infill), color = "transparent") +
  scale_fill_gradient(low = palette5[1],
                      high = palette5[length(palette5)],
                      name = "Stretched\nValues") +
  geom_sf(data = studyAreaCounties, fill = NA, colour = "black", size = 1) +
  labs(title = "Development Demand in 2040: Predicted Probabilities") +
  mapTheme

```

# 6. Comparing Predicted Development Demand & Environmental Sensitivity

We now have a really strong indicator of development demand for 2040 to help guide local land use planning. Demand however, is only one side of the equation. It must balanced with the supply of environmentally sensitive land. Understanding the interplay between demand and supply is the first stage of the ‘Allocation’ phase, where Planners ultimately decide which land should be developed and which should not.

For this analysis farmland and undeveloped land are be deemed `Suitable`, while environmentally sensitive areas like wetlands and forest are be deemed `Not Suitable`. Below, 2019 land cover data is read in and several measures of environmental sensitivity are created by county. These include:

1. The total amount of wetlands and forest land cover area in 2019.
2. The amount of sensitive land (wetland and forest) lost between 2001 and 2019.
3. The total area of large sensitive landscape ‘patches’ in 2019.

The third metric warrants some further discussion. Leapfrog development is the idea that discontinuous development across space carves out disjointed patches of habitat. This fragmentation reduces biodiversity particularly for species that need room to roam. Below, environmentally `sensitive_regions` are created to represent large areas of un-fragmented habitat. We then calculate the total area of these clumps for each county.
<br>
## 6.1. 2019 Land Cover Data  

To begin, the 2019 Land Cover data is read in and reclassified.

```{r, warning = FALSE, message = FALSE}
# Read raster data
lc_2019 <- raster("https://raw.githubusercontent.com/Yingtong-Z/sprawl-forecasting/cc191e7ec81e863672040f74745fbf9b8015b693/data/Cville_LC_2019.tif")

ggplot() +
  geom_raster(data = rbind(rast(lc_2001) %>% mutate(label = "2001"),
                           rast(lc_2019) %>% mutate(label = "2019")) %>% 
              na.omit %>% filter(value > 0), 
              aes(x,y,fill=as.factor(value))) +
  geom_sf(data = studyAreaCounties, fill = NA, colour = "red", size = 1) +
  facet_wrap(~label) +
  scale_fill_viridis(discrete=TRUE, name ="") +
  labs(title = "Land Cover, 2001 & 2019") +
  mapTheme + theme(legend.position = "none")
```

Next, each raster is aggregated to the fishnet using the `aggregateRaster` function and 2019 land cover types are mapped.

```{r, warning = FALSE, message = FALSE}
developed19 <- lc_2019 == 21 | lc_2019 == 22 | lc_2019 == 23 | lc_2019 == 24
forest19 <- lc_2019 == 41 | lc_2019 == 42 | lc_2019 == 43
farm19 <- lc_2019 == 81 | lc_2019 == 82
wetlands19 <- lc_2019 == 90 | lc_2019 == 95
otherUndeveloped19 <- lc_2019 == 52 | lc_2019 == 71 | lc_2019 == 31
water19 <- lc_2019 == 11

names(developed19) <- "developed19"
names(forest19) <- "forest19"
names(farm19) <- "farm19"
names(wetlands19) <- "wetlands19"
names(otherUndeveloped19) <- "otherUndeveloped19"
names(water19) <- "water19"

theRasterList19 <- c(developed19,forest19,farm19,wetlands19,otherUndeveloped19,water19)

###assign lc values based on hierarchy
dat2 <-
  aggregateRaster(theRasterList19, dat_infill) %>%
  dplyr::select(developed19,forest19,farm19,wetlands19,otherUndeveloped19,water19) %>%
  st_set_geometry(NULL) %>%
  bind_cols(.,dat) %>%
  st_sf() %>%
  st_cast("POLYGON")
# reassign cells with more than one lc value to just one based on hierarchy shown here
dat2 <- dat2 %>%
    mutate(farm19 = ifelse(developed19 == 0 & farm19 == 1, 1, 0)) %>%
    mutate(forest19 = ifelse(developed19 == 0 & farm19 == 0 & forest19 == 1, 1, 0)) %>%
    mutate(wetlands19 = ifelse(developed19 == 0 & farm19 == 0 & forest19 == 0 & wetlands19 == 1, 1, 0)) %>%
    mutate(water19 = ifelse(developed19 == 0 & farm19 == 0 & forest19 == 0 & wetlands19 == 0 & water19 == 1, 1, 0)) %>%
    mutate(otherUndeveloped19 = ifelse(developed19 == 0 & farm19 == 0 & forest19 == 0 & wetlands19 == 0 & water19 == 0 & otherUndeveloped19 == 1, 1, 0))


dat2 %>%
  gather(var,value,developed19:water19) %>%
  st_centroid() %>%
  mutate(X = st_coordinates(.)[,1],
         Y = st_coordinates(.)[,2]) %>%
  ggplot() +
    geom_sf(data=SJ__Grid) +
    geom_point(aes(X,Y, colour=as.factor(value)), size = 0.1) +
    facet_wrap(~var) +
    scale_colour_manual(values = palette2,
                        labels=c("Other","Land Cover"),
                        name = "") +
    labs(title = "Land Cover Types, 2019",
         subtitle = "As fishnet centroids") +
   mapTheme

```

Next, we reformat 2019 Land Cover for our Model, preserving 2001 features as new columns.

```{r, warning = FALSE, message = FALSE}
dat2 <- dat2 %>%
# 2001 land cover
    mutate(farm01 = farm) %>%
    mutate(forest01 = forest) %>%
    mutate(wetlands01 = wetlands) %>%
    mutate(water01 = water) %>%
    mutate(otherUndeveloped01 = otherUndeveloped) %>%
    mutate(total_housing_units01 = total_housing_units) %>%
    mutate(total_white01 = total_white) %>% 
# 2019 land cover
    mutate(farm = farm19) %>%
    mutate(forest = forest19) %>%
    mutate(wetlands = wetlands19) %>%
    mutate(water = water19) %>%
    mutate(otherUndeveloped = otherUndeveloped19) %>%
    mutate(total_housing_units = total_housing_units2020) %>%
    mutate(total_white = total_white2020)
```

## 6.2. Sensitive Land Cover Lost

Below an indicator `sensitive_lost` is created indicating grid cells that were either forest or wetlands in 2001 but were no longer so in 2019. The output layer, `sensitive_land_lost`, gives a sense for how development in the recent past has effected the natural environment.

```{r, warning = FALSE, message = FALSE, fig.height = 6, fig.width= 6}
dat2 <-
  dat2 %>%
   mutate(sensitive_lost19 = ifelse(forest01 == 1 & forest19 == 0 |
                                    wetlands01 == 1 & wetlands19 == 0,1,0))
                      
ggplot() +
  geom_sf(data=dat2, aes(fill =as.factor(sensitive_lost19)), color = "transparent") +
  scale_fill_manual(values = palette2,
                      labels=c("No Change","Sensitive Lost"),
                      name = "") +
  labs(title = "Sensitive lands lost: 2001 - 2019") +
  mapTheme
```

## 6.3 Landscape Fragmentation

In this section, the `wetlands19` and `forest19` rasters are converted to contiguous `sensitive_regions` using the `raster::clump` function. This is equivalent to Region Group in ArcGIS. The raster clumps are then converted to vector `sf` layers; dissolved into unique regions; Acres are calculated; and the layers are converted back to raster to be extracted back to the fishnet with `aggregateRaster`. Note that only `sensitive_regions` with areas greater than 1 acre are included.

```{r, warning = FALSE, message = FALSE, fig.height = 6, fig.width= 6}
sensitiveRegions <- 
  raster::clump(wetlands19 + forest19) %>%
  rasterToPolygons() %>%
  st_as_sf() %>%
  group_by(clumps) %>% 
  summarize() %>%
    mutate(Acres = as.numeric(st_area(.) * 0.0000229568)) %>%
    filter(Acres > 3954)  %>%
  dplyr::select() %>%
  raster::rasterize(.,emptyRaster) 
sensitiveRegions[sensitiveRegions > 0] <- 1  
names(sensitiveRegions) <- "sensitiveRegions"

dat2 <-
  aggregateRaster(c(sensitiveRegions), dat2) %>%
  dplyr::select(sensitiveRegions) %>%
  st_set_geometry(NULL) %>%
  bind_cols(.,dat2) %>%
  st_sf()

ggplot() +
    geom_sf(data=dat2, aes(fill =as.factor(sensitiveRegions)), color = "transparent") +
  scale_fill_manual(values = palette2,
                      labels=c("Other","Sensitive Regions"),
                      name="") +
  labs(title = "Sensitive regions",
       subtitle = "Continous areas of either wetlands or forests\ngreater than 1 acre") +
  mapTheme
```

## 6.4. Summarize by County

The below `dplyr` statement takes as its input, `dat2`, which was created in Sections 6.2 - 6.4 and wrangles together a table of county-level, supply and demand metrics which can be used to analyze suitability by county.
```{r, warning = FALSE, message = FALSE}
county_specific_metrics <- 
  dat2 %>%
  #predict development demand from our model
  mutate(Development_Demand = predict(Model6, dat2, type="response")) %>%
  #get a count count of grid cells by county which we can use to calculate rates below
  left_join(st_set_geometry(dat, NULL) %>% group_by(NAME) %>% summarize(count = n())) %>%
  #calculate summary statistics by county
  group_by(NAME) %>%
  summarize(Total_Farmland = sum(farm19) / max(count),
            Total_Forest = sum(forest19) / max(count),
            Total_Wetlands = sum(wetlands19) / max(count),
            Total_Undeveloped = sum(otherUndeveloped19) / max(count),
            Sensitive_Land_Lost = sum(sensitive_lost19) / max(count),
            Sensitive_Regions = sum(sensitiveRegions) / max(count),
            Mean_Development_Demand = mean(Development_Demand)) %>%
  #get population data by county
  left_join(countyPopulation_2040 %>% 
            mutate(Population_Change = county_projection_2040 - county_population_2020,
                   Population_Change_Rate = Population_Change / county_projection_2040) %>%
            dplyr::select(NAME,Population_Change_Rate))
```


Now a small multiple plot can be created providing both supply and demand side analytics by county. The plot gives a sense for development demand (`Demand-Side`), suitable land for development (`Suitable`) and sensitive land (`Not Suitable`).

The data suggests both population and development demand will increase for Charlottesville MSA. However, compared to Charlottesville county, Albemarle has a high rate of developable farmland and a low supply of sensitive land. This suggests Albemarle is more suitable to new development than Charlottesville, which is highly developed.

```{r, warning = FALSE, message = FALSE}
county_specific_metrics %>%
  gather(Variable, Value, -NAME, -geometry) %>%
  mutate(Variable = factor(Variable, levels=c("Population_Change_Rate","Mean_Development_Demand",
                                              "Total_Farmland","Total_Undeveloped","Total_Forest",
                                              "Total_Wetlands","Sensitive_Land_Lost","Sensitive_Regions",
                                              ordered = TRUE))) %>%
  mutate(Planning_Designation = case_when(
    Variable == "Population_Change_Rate" | Variable == "Mean_Development_Demand" ~ "Demand-Side",
    Variable == "Total_Farmland" | Variable == "Total_Undeveloped"               ~ "Suitable",
    TRUE                                                                         ~ "Not Suitable")) %>%
  ggplot(aes(x=Variable, y=Value, fill=Planning_Designation)) +
    geom_bar(stat="identity", position=position_dodge(), colour="black") +
    facet_wrap(~NAME, ncol=5) +
    coord_flip() +
    scale_y_continuous(breaks = seq(.25, 1, by = .25)) +
    geom_vline(xintercept = 2.5) + geom_vline(xintercept = 4.5) +
    scale_fill_manual(values=c("black","red","darkgreen")) +
    labs(title= "County Specific Allocation Metrics", subtitle= "As rates", x="Indicator", y="Rate") +
    plotTheme + theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position="bottom")
```

# 7. Allocation

Allocation is the final stage of the urban growth modeling process. Now that both demand and supply is understood, We can allocate development rights accordingly. Of course, this could take many forms of regulation including zoning, subdivision approval or outright conservation. In this section, demand and supply are visualized for two counties, Charlottesville and Albemarle. The data suggests that the latter is more conducive to growth while the former is less so.

First, development demand is predicted for Albemarle. Then a layer, `Albemarle_landUse` is created, that includes indicators for both previously developed land and environmentally unsuitable land. This layer then is overlayed atop development demand and projected population change to give the full supply and demand-side picture in Albemarle.

There are some clear opportunities for development in Albemarle. Significant infill opportunities exist along the roads and highways where population change is projected to be greatest. There is also a good deal of environmentally suitable land along the highways. This would be ideal space for land developments.

```{r, warning = FALSE, message = FALSE, fig.height= 8, fig.width= 11}
Albemarle <-
  dat2 %>%   #calculate population change
    left_join(countyPopulation_2040) %>%
    mutate(proportion_of_county_pop = total_population2020 / county_population_2020,
           pop_2040.infill = proportion_of_county_pop * county_projection_2040,
           pop_Change = (pop_2040.infill - total_population2020)) %>%
    dplyr::select(-county_projection_2040, -county_population_2020, 
                  -proportion_of_county_pop, -pop_2040.infill) %>%
    mutate(Development_Demand = predict(Model6, dat2, type="response")) %>%
    filter(NAME == "Albemarle") 


Albemarle_landUse <- rbind(
  filter(Albemarle, forest19 == 1 | wetlands19 == 1 ) %>%
  dplyr::select() %>% mutate(Land_Use = "Not Suitable"),
  filter(Albemarle, developed19 == 1) %>%
  dplyr::select() %>% mutate(Land_Use = "Developed"))

grid.arrange(
ggplot() +
  geom_sf(data=Albemarle, aes(fill=factor(ntile(Development_Demand,5))), colour=NA) +
  geom_point(data=Albemarle_landUse, aes(x=xyC(Albemarle_landUse)[,1],
                                        y=xyC(Albemarle_landUse)[,2], colour=Land_Use),
                                        shape = 16, size = 0.25) +
  geom_sf(data=st_intersection(CvilleHighways,filter(studyAreaCounties, NAME=="Albemarle")), size=2) +
  scale_fill_manual(values = palette5, name="Development_Demand",
                    labels=substr(quintileBreaks(Albemarle,"Development_Demand"),1,5)) +
  scale_colour_manual(values = c("black","red")) +
  labs(title = "Development Potential, \n2040: Albemarle") + mapTheme +
  guides(fill = guide_legend(order = 1), colour = guide_legend(order = 2)),

ggplot() +
  geom_sf(data=Albemarle, aes(fill=factor(ntile(pop_Change,5))), colour=NA) +
  geom_point(data=Albemarle_landUse, aes(x=xyC(Albemarle_landUse)[,1],
                                        y=xyC(Albemarle_landUse)[,2], colour=Land_Use),
                                        shape = 16, size = 0.25) +
  geom_sf(data=st_intersection(CvilleHighways,filter(studyAreaCounties, NAME=="Albemarle")), size=2) +
  scale_fill_manual(values = palette5, name="Population_Change",
                    labels=substr(quintileBreaks(Albemarle,"pop_Change"),1,5)) +
  scale_colour_manual(values = c("black","red")) +
  labs(title = "Projected Population, \n2040: Albemarle") + mapTheme +
  guides(fill = guide_legend(order = 1), colour = guide_legend(order = 2)), ncol=2)

```

The plots above are created using a `ggplot` trick to show our fishnet grid cells overlayed by color-coded points. 

For comparison purposes, this process is replicated for Charlottesville county below.

```{r, warning = FALSE, message = FALSE, fig.height= 8, fig.width= 11}
Charlottesville <-
  dat2 %>%   #calculate population change
    left_join(countyPopulation_2040) %>%
    mutate(proportion_of_county_pop = total_population2020 / county_population_2020,
           pop_2040.infill = proportion_of_county_pop * county_projection_2040,
           pop_Change = (pop_2040.infill - total_population2020)) %>%
    dplyr::select(-county_projection_2040, -county_population_2020, 
                  -proportion_of_county_pop, -pop_2040.infill) %>%
    mutate(Development_Demand = predict(Model6, dat2, type="response")) %>%
    filter(NAME == "Charlottesville") 


Charlottesville_landUse <- rbind(
  filter(Charlottesville, forest19 == 1 | wetlands19 == 1 ) %>%
  dplyr::select() %>% mutate(Land_Use = "Not Suitable"),
  filter(Charlottesville, developed19 == 1) %>%
  dplyr::select() %>% mutate(Land_Use = "Developed"))

grid.arrange(
ggplot() +
  geom_sf(data=Charlottesville, aes(fill=factor(ntile(Development_Demand,5))), colour=NA) +
  geom_point(data=Charlottesville_landUse, aes(x=xyC(Charlottesville_landUse)[,1],
                                        y=xyC(Charlottesville_landUse)[,2], colour=Land_Use),
                                        shape = 16, size = 1) +
  scale_fill_manual(values = palette5, name="Development_Demand",
                    labels=substr(quintileBreaks(Charlottesville,"Development_Demand"),1,5)) +
  scale_colour_manual(values = c("black","red")) +
  labs(title = "Development Potential, \n2040: Charlottesville") + mapTheme +
  guides(fill = guide_legend(order = 1), colour = guide_legend(order = 2)),

ggplot() +
  geom_sf(data=Charlottesville, aes(fill=factor(ntile(pop_Change,5))), colour=NA) +
  geom_point(data=Charlottesville_landUse, aes(x=xyC(Charlottesville_landUse)[,1],
                                        y=xyC(Charlottesville_landUse)[,2], colour=Land_Use),
                                        shape = 16, size = 1) +
  scale_fill_manual(values = palette5, name="Population_Change",
                    labels=substr(quintileBreaks(Albemarle,"pop_Change"),1,5)) +
  scale_colour_manual(values = c("black","red")) +
  labs(title = "Projected Population, \n2040: Charlottesville") + mapTheme +
  guides(fill = guide_legend(order = 1), colour = guide_legend(order = 2)), ncol=2)

```

# 8. Conclusion

We stop short of actually allocating land to development. While our model is well-suited for understanding sprawl-style development, it is not useful for understanding how new demand might be absorbed by upzoning and densification of existing development. It would not be wise to allocate the entire projected population to undeveloped land. Instead, we’d prefer a more nuanced understanding of how local land use laws might play a role. At this stage in the analysis however, the Planner has all they need to engage local stakeholders about future development decisions.

Next, we ran the same script with a new highways dataset upgrading an existing road connecting Charlottesville and Crozet to a highway to see how this new infrastructure might impact urban growth projections. Here are those results for Albemarle:

![Albemarle County](https://raw.githubusercontent.com/Yingtong-Z/sprawl-forecasting/c351e88031af508ca19f108071b0e7008e4cc36c/graph/Allocation2.3A.jpeg)

And here are the results for Charlottesville:

![Charlottesville County](https://raw.githubusercontent.com/Yingtong-Z/sprawl-forecasting/c351e88031af508ca19f108071b0e7008e4cc36c/graph/Allocation2.3C.jpeg)

Html for this script is linked [here](https://yingtong-z.github.io/sprawl-forecasting/R-scripts/2.3--urban_growth_modeling_Charlottesville.html)