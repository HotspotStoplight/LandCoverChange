---
output: github_document
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
rm(list=ls())

```

lulcc provides a framework for spatially explicit land use change modelling in r. The long term goal of lulcc is to  provide a smart and tidy interface to running the standard land use change modelling in 4 steps: raster data prepping, probability surface generation, allocation and validation, in one tidy package.

## Installation

You can install the released version of lulcc from [CRAN](https://CRAN.R-project.org) with:

``` {r}
# install.packages("lulcc")
```

And the development version from [GitHub](https://github.com/) with:

``` {r}
# install.packages("devtools")
# devtools::install_github("simonmoulds/lulcc")
```
## The lulcc workflow
*Adapted from https://www.geosci-model-dev.net/8/3215/2015/*

```{r LoadLibraries}
if (!"googleCloudStorageR" %in% rownames(installed.packages())) {
    install.packages("googleCloudStorageR", dependencies = TRUE)
}
library(googleCloudStorageR)

library(lulcc)
library(raster)
library(rasterVis)
```



### 1. Raster data preparation

Land use change modelling requires a large amount of input data. The most important input is at least one map of observed land use. In lulcc, this data is represented by the `ObsLulcRasterStack` class:

Load Files Locally
```{r LoadAndPrep}
# Define variables
bucket_name <- "hotspotstoplight_landcoverchange"
crop_res <- "crop6_30m"
input_folder <- "input"
output_folder <- "output"

# Set the default bucket name
gcs_global_bucket(bucket_name)

# List all files in the input directory
input_path <- file.path(input_folder, crop_res)
files_info <- gcs_list_objects(prefix = input_path)

# Extract names of the files
files_names <- sapply(files_info, function(x) x$name)

# Filter for .RData files
rdata_files <- files_names[grepl("\\.RData$", files_names)]

# Function to download and load an RData file
load_rdata_gcs <- function(file_name) {
  temp_file <- tempfile()
  gcs_get_object(file_name, saveToDisk = temp_file)
  load(temp_file, .GlobalEnv)
  unlink(temp_file) # Clean up temporary file
}

# Load each .RData file
lapply(rdata_files, load_rdata_gcs)

```

Define Obs Variable
```{r DefineObsVariable}
obs <- ObsLulcRasterStack(x=LandCover,
                          pattern="lc",
                          categories=c(1,2,3,4),
                          labels=c('Forest', 'Other', 'Built', 'Water'),
                          t=c(0,10))
```


```{r PlotLandCoverRasters, fig.width=12, fig.height=6.75}
# Assuming your ObsLulcRasterStack 'obs' is compatible with raster plotting
# Extract layers by time points (assuming two time points for simplicity)
lc_2013_raster <- raster(obs, layer=1)
lc_2023_raster <- raster(obs, layer=2)

# Plot the first time point
plot(lc_2013_raster, main="Land Cover 2013", col=c('darkgreen', 'tan', 'red', 'blue'), breaks=c(0.5, 1.5, 2.5, 3.5, 4.5), legend=FALSE)
legend("topright", legend=c('Forest', 'Other', 'Built', 'Water'), fill=c('darkgreen', 'tan', 'red', 'blue'))

# Plot the second time point
plot(lc_2023_raster, main="Land Cover 2023", col=c('darkgreen', 'tan', 'red', 'blue'), breaks=c(0.5, 1.5, 2.5, 3.5, 4.5), legend=FALSE)
legend("topright", legend=c('Forest', 'Other', 'Built', 'Water'), fill=c('darkgreen', 'tan', 'red', 'blue'))

```

A useful starting point in land use change modelling is to obtain a transition matrix for two observed land use maps to identify the main transitions. This can be achieved with the `crossTabulate` function:

```{r CrossTabulate, echo=TRUE}
# obtain a transition matrix from land use maps for 1985 and 1991
crossTabulate(obs, times=c(0,10))
```

The next stage is to relate observed land use or observed land use transitions to spatially explicit biophysical or socioeconomic explanatory variables. These are loaded as follows:

```{r PrepVars}
ef <- ExpVarRasterList(x=Factors, pattern="ef")
```

### 2. Probability surface modelling

To fit predictive models we first divide the study region into training and testing partitions. The `partition` function returns a list with cell numbers for each partition:

```{r Partition}
part <- partition(x=obs[[1]],
                  size=0.1, spatial=TRUE)
```

We then extract cell values for the training and testing partitions.

```{r TrainTest}
# extract training data
train.data <- getPredictiveModelInputData(obs=obs,
                                          ef=ef,
                                          cells=part[["train"]],
                                          t=0)

test.data <- getPredictiveModelInputData(obs=obs,
                                         ef=ef,
                                         cells=part[["test"]])
```

Predictive models are represented by the `PredictiveModelList` class. For comparison, we create a `PredictiveModelList` object for each type of predictive model:

```{r Modelling}
# fit models (note that a predictive model is required for each land use category)
# Factors <- stack(pop2010, slope, dist_urban, dist_road, dist_highway)

forms <- list(Forest~ef_01+ef_02+ef_03+ef_04+ef_05,
              Other~ef_01+ef_02+ef_03+ef_04+ef_05,
              Built~ef_01+ef_02+ef_03+ef_04+ef_05,
              Water~ef_01+ef_02+ef_03+ef_04+ef_05)

# generalized linear model models
glm.models <- glmModels(formula=forms,
                        family=binomial,
                        data=train.data,
                        obs=obs)

# recursive partitioning and regression tree models
# rpart.models <- rpartModels(formula=forms,
#                             data=train.data,
#                             obs=obs)

# random forest models (WARNING: takes a long time!)
rf.models <- randomForestModels(formula=forms,
                                data=train.data,
                                obs=obs,
                                na.action=na.omit)

```

We can then use the fitted models to predict over the full data set and produce the probability surfaces for each fitted model:

```{r ProbabilityMaps, echo = TRUE, fig.width=10}
all.data <- as.data.frame(x=ef, obs=obs, cells=part[["all"]])

probmaps <- predict(object=rf.models,
                    newdata=all.data,
                    data.frame=TRUE)
points <- rasterToPoints(obs[[1]], spatial=TRUE)
probmaps <- SpatialPointsDataFrame(points, probmaps)
probmaps <- rasterize(x=probmaps, y=obs[[1]],
                      field=names(probmaps))
rasterVis::levelplot(probmaps)
```
# OUTPUT PROBABILITY RASTERS
```{r OutputProbabilityRasters}
# Loop through each band of the raster stack
for (i in 1:nlayers(probmaps)) {
  # Extract the single band
  single_band <- raster(probmaps, layer = i)

  # Create a filename from the band's name
  filename <- paste0(names(single_band), ".tif")
  
  # Create a temporary file path
  temp_file <- tempfile(fileext = ".tif")

  # Write the single band raster to a temporary TIFF file
  writeRaster(single_band, temp_file, format = "GTiff", overwrite = TRUE)
  
  # Construct the full path for GCS upload
  full_path <- file.path(output_folder, crop_res, filename)
  
  # Upload the TIFF file to Google Cloud Storage
  gcs_upload_object(temp_file, full_path)

  # Optionally, remove the temporary file to free up space
  unlink(temp_file)
}

```


Model performance is assessed using the receiver operator characteristic provided by the [ROCR](http://cran.r-project.org/web/packages/ROCR/index.html) package. lulcc includes classes `Prediction` and `Performance` which extend the native ROCR classes to contain multiple `prediction` and `performance` objects. The procedure to obtain these objects and assess performance is as follows:

```{r Performances, echo = TRUE}
#GLM
glm.pred <- PredictionList(models=glm.models,
                           newdata=test.data)
glm.perf <- PerformanceList(pred=glm.pred,
                            measure="rch")
#RPART
# rpart.pred <- PredictionList(models=rpart.models,
#                              newdata=test.data)
# rpart.perf <- PerformanceList(pred=rpart.pred,
#                               measure="rch")

#Random Forest
rf.pred <- PredictionList(models=rf.models,
                          newdata=test.data)
rf.perf <- PerformanceList(pred=rf.pred,
                           measure="rch")
#Plot ROC Curves
plot(list(glm=glm.perf,
          rf=rf.perf))
```

Export ROC Curves
```{r ROC_Curves}
# Create a temporary file path for the plot
temp_file <- tempfile(fileext = ".png")

# Specify the file path and name, along with desired dimensions for the PNG plot
png(temp_file, width = 1600, height = 900)

# Your plotting code
plot(list(glm=glm.perf, rf=rf.perf))

# Close the plotting device
dev.off()

# Construct the full path for GCS upload
full_path <- file.path(output_folder, crop_res, "ROC_Curves.png")

# Upload the PNG file to Google Cloud Storage
gcs_upload_object(temp_file, full_path)

# Optionally, remove the temporary file to free up space
unlink(temp_file)

```

### 3. Allocation

Spatially explicit land use change models are usually driven by non-spatial estimates of land use area for each timestep in the simulation.
While many complex methods have been devised, in lulcc we simply provide a method for linear extrapolation of land use change, which relies on there being at least two observed land use maps:

```{r DemandTest}
# set variable timewindow for testing
timewindow <- c(0,10)

# obtain demand scenario from extrapolated land use change
dmd <- approxExtrapDemand(obs=obs, t=timewindow)
dmd
```

We then use a filter defined as a matrix within the `NeighbRasterStack` function to gather neighbor data from the land use change data.
```{r NeighborModelTest}
w <- matrix(data=1, nrow=3, ncol=3)
nb <- NeighbRasterStack(x=obs[[1]], weights=w,
                        categories=c(1,2,3,4))
histRaster <- obs[[1]]  # This extracts the first layer as a RasterLayer
```

The culmination of the modelling process is to simulate the location of land use change. lulcc provides a routine based on the CLUE-S model (Verburg et al., 2002) and a novel stochastic allocation procedure (with option for using the ordered method). The first step is to combine the various model inputs to ensure they are compatible:

```{r CLUESModelTest}
clues.rules <- matrix(data=1, nrow=4, ncol=4)

clues.parms <- list(jitter.f=0.0002,
                    scale.f=0.000001,
                    max.iter=5000,
                    max.diff=50,
                    ave.diff=50)

clues.model <- CluesModel(obs=obs,
                          ef=ef,
                          models=rf.models,
                          time=timewindow,
                          demand=dmd,
                          hist=histRaster,
                          # mask=dummyMask,
                          neighb=nb,
                          elas=c(0.2,0.2,0.2,0.2),
                          rules=clues.rules,
                          params=clues.parms)

ordered.model <- OrderedModel(obs=obs,
                              ef=ef,
                              models=rf.models,
                              time=timewindow,
                              demand=dmd,
                              order=c(3,2,1,4))
```

Allocate demand to the models
```{r AllocationTest}
clues.model <- allocate(clues.model)
ordered.model <- allocate(ordered.model, stochastic=TRUE)
```

# Plot and Output Rasters
Clue-S Model Test
```{r CluesTest, fig.width=10}
# Assuming 'clues.model' is your CluesModel object
clues_output <- clues.model@output

clues_output_2013 <- ordered.model@output[[1]]
clues_output_2023 <- ordered.model@output[[2]]

# Plotting with rasterVis
levelplot(clues_output, 
          col.regions=colorRampPalette(c("darkgreen", "tan", "red", "blue")),
          # col.regions=colorRampPalette(c("darkgreen", "tan", "red")),   
          main="Future Land Use Categories (CLUE-S)")

num_layers <- nlayers(clues.model@output)
print(num_layers)
```

Ordered Model Test
```{r OrderedTest, fig.width=10}
# Check if ordered.model@output is a list and contains raster objects
if("list" %in% class(ordered.model@output) && all(sapply(ordered.model@output, function(x) inherits(x, "Raster")))) {
  for(i in seq_along(ordered.model@output)) {
    # Attempt to safely modify the raster values
    try({
      current_raster <- ordered.model@output[[i]]
      # Ensure the object is a RasterLayer
      if(inherits(current_raster, "RasterLayer")) {
        # Manually reassign values
        values(current_raster)[values(current_raster) == -1] <- 1
        ordered.model@output[[i]] <- current_raster
      }
    }, silent = TRUE)
  }
} else {
  message("The ordered.model@output does not contain a modifiable list of Raster objects.")
}


# # Plotting with rasterVis
# levelplot(ordered.model@output,
#           col.regions=colorRampPalette(c("darkgreen", "tan", "red", "blue")),
#           main="Land Use Categories (Random Forest ModelOrdered)")

# Generate individual plots with specific titles
plot1 <- levelplot(ordered.model@output[[1]], 
                   col.regions=colorRampPalette(c("darkgreen", "tan", "red", "blue")),
                   main="2013 Land Cover")

plot2 <- levelplot(ordered.model@output[[2]], 
                   col.regions=colorRampPalette(c("darkgreen", "tan", "red", "blue")),
                   main="2023 Land Cover")

# Arrange the plots together
grid.arrange(plot1, plot2, ncol=1)

```


### 4. Validation

An important yet frequently overlooked aspect of land use change modelling is model validation. lulcc provides a recent validation method developed by Pontius et al. (2011), which simultaneously compares a reference (observed) map for time 1, a reference map for time 2 and a simulated map for time 2. The first step in this method is to calculate three dimensional contingency tables:

```{r ThreemapComparison}
# evaluate CLUE-S model output
clues.tabs <- ThreeMapComparison(x=clues.model,
                                   factors=c(1, 2, 4),
                                   timestep=10)

ordered.tabs <- ThreeMapComparison(x=ordered.model,
                                   factors=c(1, 2, 4),
                                   timestep=10)
```

From these tables we can easily extract information about different types of agreement and disagreement as well as compute summary statistics such as the figure of merit:
Agreement Plot
```{r AgreementBudget, echo=TRUE}
clues.agr <- AgreementBudget(x=clues.tabs)
plot(clues.agr)

ordered.agr <- AgreementBudget(x=ordered.tabs)
plot(ordered.agr)
```

Export Agreement Plot
```{r AgreementPlotExport}
# Function to create and upload a plot
create_and_upload_plot <- function(plot_code, plot_name) {
  # Create a temporary file path for the plot
  temp_file <- tempfile(fileext = ".png")
  
  # Start PNG device with the temporary file path
  png(temp_file, width = 1600, height = 900)
  
  # Execute the plotting code
  plot_code()
  
  # Close the plotting device
  dev.off()
  
  # Construct the full path for GCS upload
  full_path <- file.path(output_folder, crop_res, plot_name)
  
  # Upload the PNG file to Google Cloud Storage
  gcs_upload_object(temp_file, full_path)
  
  # Remove the temporary file to free up space
  unlink(temp_file)
}

# Create and upload "Clue-S AgreementBudget.png"
create_and_upload_plot(plot_code = function() plot(clues.agr), plot_name = "Clue-S_AgreementBudget.png")

# Create and upload "Ordered AgreementBudget.png"
create_and_upload_plot(plot_code = function() plot(ordered.agr), plot_name = "Ordered_AgreementBudget.png")

```

```{r FigureOfMerit, echo=TRUE}
# clues.fom <- FigureOfMerit(x=clues.agr)
# plot(clues.fom, from=1, to=2)
# plot(clues.fom, from=1, to=3)
# plot(clues.fom, from=2, to=3)
# 
# ordered.fom <- FigureOfMerit(x=ordered.agr)
# plot(ordered.fom, from=1, to=2)
# plot(ordered.fom, from=1, to=3)
# plot(ordered.fom, from=2, to=3)
```

### 4. Extrapolation
Clue-S Model
<br>
Demand Estimation
```{r DemandExtrapolation}
# set variable timewindow for extrapolating land cover change to 2100
timewindow <- c(0,10,37)

# obtain demand scenario from extrapolated land use change
dmd <- approxExtrapDemand(obs=obs, t=timewindow)
dmd
```

Manually-assign demand (scenario-based modeling)
```{r ManualDemandSpecificaiton}
# # Example demand data for timesteps 0 and 10
# dmd <- data.frame(
#   timestep = c(0, 10),
#   Forest = c(forest_area_at_0, forest_area_at_10),
#   Other = c(other_area_at_0, other_area_at_10),
#   Built = c(built_area_at_0, built_area_at_10),
#   Water = c(water_area_at_0, water_area_at_10)
# )
```

Gather neighbor data from the land use change data.
```{r NeighborData}
w <- matrix(data=1, nrow=3, ncol=3)
nb <- NeighbRasterStack(x=obs[[1]], weights=w,
                        categories=c(1,2,3,4))
histRaster <- obs[[1]]  # This extracts the first layer as a RasterLayer
```

The culmination of the modelling process is to simulate the location of land use change. lulcc provides a routine based on the CLUE-S model (Verburg et al., 2002) and a novel stochastic allocation procedure (with option for using the ordered method). The first step is to combine the various model inputs to ensure they are compatible:

```{r CLUES_Model}
clues.rules <- matrix(data=1, nrow=4, ncol=4)

clues.parms <- list(jitter.f=0.0002,
                    scale.f=0.000001,
                    max.iter=5000,
                    max.diff=50,
                    ave.diff=50)

clues.model <- CluesModel(obs=obs,
                          ef=ef,
                          models=rf.models,
                          time=timewindow,
                          demand=dmd,
                          hist=histRaster,
                          # mask=dummyMask,
                          neighb=nb,
                          elas=c(0.2,0.2,0.2,0.2),
                          rules=clues.rules,
                          params=clues.parms)

clues.model <- allocate(clues.model)
```

# Plot and Output Rasters
Clue-S Model Test
```{r CluesVisualization, fig.width=10}
# Assuming 'clues.model' is your CluesModel object
clues_output <- clues.model@output

# Plotting with rasterVis
levelplot(clues_output, 
          col.regions=colorRampPalette(c("darkgreen", "tan", "red", "blue")), 
          main="Future Land Use Categories (CLUE-S)")

```

# 5. Exporting Rasters 
```{r ExportRasters}
# Function to write and upload a raster
upload_raster <- function(raster_obj, file_name) {
  # Create a temporary file
  temp_file <- tempfile(fileext = ".tif")
  
  # Write the raster to the temporary file
  writeRaster(raster_obj, filename = temp_file, format = "GTiff", overwrite = TRUE)
  
  # Construct the full path for GCS upload
  full_path <- file.path(output_folder, crop_res, file_name)
  
  # Upload the TIFF file to Google Cloud Storage
  gcs_upload_object(temp_file, full_path)
  
  # Remove the temporary file to free up space
  unlink(temp_file)
}

# Extract the second band for 2050 land cover data
lc_2050 <- raster(clues_output, layer=2)
# Export and upload 2050 land cover data
upload_raster(lc_2050, "lc_2050.tif")

# Assume lc_2023_raster is already defined and ready
# Export and upload 2023 land cover data
upload_raster(lc_2023_raster, "lc_2023.tif")


```

```{r CurrentFutureLandCoverPlots}
plot(lc_2023_raster)
plot(lc_2050)

```

