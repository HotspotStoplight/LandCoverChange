---
output: github_document
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
rm(list=ls())

```

lulcc provides a framework for spatially explicit land use change modelling in r. The long term goal of lulcc is to  provide a smart and tidy interface to running the standard land use change modelling in 4 steps: raster data prepping, probability surface generation, allocation and validation, in one tidy package.

## Installation

You can install the released version of lulcc from [CRAN](https://CRAN.R-project.org) with:

``` {r}
# install.packages("lulcc")
```

And the development version from [GitHub](https://github.com/) with:

``` {r}
# install.packages("devtools")
# devtools::install_github("simonmoulds/lulcc")
```
## The lulcc workflow
*Adapted from https://www.geosci-model-dev.net/8/3215/2015/*

```{r LoadLibraries}
if (!"googleCloudStorageR" %in% rownames(installed.packages())) {
    install.packages("googleCloudStorageR", dependencies = TRUE)
}
library(googleCloudStorageR)

if (!"gargle" %in% rownames(installed.packages())) {
    install.packages("gargle", dependencies = TRUE)
}
library(gargle)

# if (!"Hmisc" %in% rownames(installed.packages())) {
#     install.packages("Hmisc", dependencies = TRUE)
# }
# library(Hmisc)

library(lulcc)
library(raster)
library(rasterVis)
```


```{r Load Data from Google Cloud}
## Fetch token. See: https://developers.google.com/identity/protocols/oauth2/scopes
scope <-c("https://www.googleapis.com/auth/cloud-platform")
token <- token_fetch(scopes = scope)

## Pass your token to gcs_auth
gcs_auth(token = token)

# set default bucket
gcs_global_bucket("hotspotstoplight_landcoverchange")

## Show objects
objects <- gcs_list_objects(bucket = "hotspotstoplight_landcoverchange", prefix = "data/")

# Loop through the objects and download each file
for (i in seq_along(objects$name)) {
  file_path <- objects$name[[i]]
  save_path <- paste("data/", basename(file_path), sep = "")
  gcs_get_object(file_path, saveToDisk = save_path, overwrite = TRUE)
}

# Load the first .RData file
load("data/Factors.RData")

# Load the second .RData file
load("data/LandCover.RData")

```

```{r define output variables}
# Define output folder and crop result for demonstration
output_folder <- "data"  # Local directory to store plots
outputs <- "outputs"   # Subfolder
```


```{r DefineObsVariable}
obs <- ObsLulcRasterStack(x=LandCover,
                          pattern="lc",
                          categories=c(1,2,3,4),
                          labels=c('Forest', 'Other', 'Built', 'Water'),
                          t=c(0,10))
```

```{r PlotLandCoverRasters, fig.width=12, fig.height=6.75}
# # Assuming your ObsLulcRasterStack 'obs' is compatible with raster plotting
# # Extract layers by time points (assuming two time points for simplicity)
# lc_2013_raster <- raster(obs, layer=1)
# lc_2023_raster <- raster(obs, layer=2)
# 
# # Plot the first time point
# plot(lc_2013_raster, main="Land Cover 2013", col=c('darkgreen', 'tan', 'red', 'blue'), breaks=c(0.5, 1.5, 2.5, 3.5, 4.5), legend=FALSE)
# legend("topright", legend=c('Forest', 'Other', 'Built', 'Water'), fill=c('darkgreen', 'tan', 'red', 'blue'))
# 
# # Plot the second time point
# plot(lc_2023_raster, main="Land Cover 2023", col=c('darkgreen', 'tan', 'red', 'blue'), breaks=c(0.5, 1.5, 2.5, 3.5, 4.5), legend=FALSE)
# legend("topright", legend=c('Forest', 'Other', 'Built', 'Water'), fill=c('darkgreen', 'tan', 'red', 'blue'))

```

```{r CrossTabulate, echo=TRUE}
# obtain a transition matrix from land use maps for 1985 and 1991
crossTabulate(obs, times=c(0,10))
```

```{r PrepVars}
ef <- ExpVarRasterList(x=Factors, pattern="ef")
```

```{r Partition}
part <- partition(x=obs[[1]],
                  size=0.1, spatial=TRUE)
```

```{r TrainTest}
# extract training data
train.data <- getPredictiveModelInputData(obs=obs,
                                          ef=ef,
                                          cells=part[["train"]],
                                          t=0)

test.data <- getPredictiveModelInputData(obs=obs,
                                         ef=ef,
                                         cells=part[["test"]])
```

```{r Modelling}
# fit models (note that a predictive model is required for each land use category)
# Factors <- stack(pop2010, slope, dist_urban, dist_road, dist_highway)

forms <- list(Forest~ef_01+ef_02+ef_03+ef_04+ef_05,
              Other~ef_01+ef_02+ef_03+ef_04+ef_05,
              Built~ef_01+ef_02+ef_03+ef_04+ef_05,
              Water~ef_01+ef_02+ef_03+ef_04+ef_05)

# generalized linear model models
glm.models <- glmModels(formula=forms,
                        family=binomial,
                        data=train.data,
                        obs=obs)

# recursive partitioning and regression tree models
# rpart.models <- rpartModels(formula=forms,
#                             data=train.data,
#                             obs=obs)

# random forest models (WARNING: takes a long time!)
rf.models <- randomForestModels(formula=forms,
                                data=train.data,
                                obs=obs,
                                na.action=na.omit)

```


```{r ProbabilityMaps, echo = TRUE, fig.width=10}
all.data <- as.data.frame(x=ef, obs=obs, cells=part[["all"]])

probmaps <- predict(object=rf.models,
                    newdata=all.data,
                    data.frame=TRUE)
points <- rasterToPoints(obs[[1]], spatial=TRUE)
probmaps <- SpatialPointsDataFrame(points, probmaps)
probmaps <- rasterize(x=probmaps, y=obs[[1]],
                      field=names(probmaps))
# rasterVis::levelplot(probmaps)
```

```{r OutputProbabilityRasters}
# Ensure the local output directory exists
if(!dir.exists(output_folder)) {
  dir.create(output_folder, recursive = TRUE)
}

# Loop through each band of the raster stack
for (i in 1:nlayers(probmaps)) {
  # Extract the single band
  single_band <- raster(probmaps, layer = i)

  # Create a filename from the band's name
  filename <- paste0(names(single_band), ".tif")
  
  # Construct the full path for local saving
  local_file_path <- file.path(output_folder, outputs, filename)
  dir.create(dirname(local_file_path), recursive = TRUE)  # Ensure directory exists

  # Write the single band raster to the local TIFF file
  writeRaster(single_band, local_file_path, format = "GTiff", overwrite = TRUE)
  
  # Set the GCS path which includes the folder structure within the bucket
  gcs_path <- file.path("data", outputs, filename)

  # Upload the TIFF file to Google Cloud Storage
  gcs_upload(local_file_path, name = gcs_path)

  # Optionally, remove the local file to free up space, if not needed locally
  unlink(local_file_path)
}

```

```{r Performance, echo = TRUE}
#GLM
glm.pred <- PredictionList(models=glm.models,
                           newdata=test.data)
glm.perf <- PerformanceList(pred=glm.pred,
                            measure="rch")
#RPART
# rpart.pred <- PredictionList(models=rpart.models,
#                              newdata=test.data)
# rpart.perf <- PerformanceList(pred=rpart.pred,
#                               measure="rch")

#Random Forest
rf.pred <- PredictionList(models=rf.models,
                          newdata=test.data)
rf.perf <- PerformanceList(pred=rf.pred,
                           measure="rch")
# #Plot ROC Curves
# plot(list(glm=glm.perf,
#           rf=rf.perf))
```

Export ROC Curves
```{r ROC_Curves}
# Create a temporary file path for the plot
temp_file <- tempfile(fileext = ".png")

# Specify the file path and name, along with desired dimensions for the PNG plot
png(temp_file, width = 1600, height = 900)

# Insert your plotting code here; replace 'plot(...)' with your actual plotting function
plot(list(glm=glm.perf, rf=rf.perf))

# Close the plotting device
dev.off()

# Ensure the local output directory exists
if(!dir.exists(output_folder)) {
  dir.create(output_folder, recursive = TRUE)
}

# Construct the full path for local saving and GCS upload
local_file_path <- file.path(output_folder, outputs, "ROC_Curves.png")
dir.create(dirname(local_file_path), recursive = TRUE)  # Ensure directory exists

# Copy the file from temp location to the local desired path
file.copy(temp_file, local_file_path)

# Set the GCS path which includes the folder structure within the bucket
gcs_path <- file.path("data", outputs, "ROC_Curves.png")

# Upload the PNG file to Google Cloud Storage
gcs_upload(local_file_path, name = gcs_path)

# Optionally, remove the temporary file to free up space
unlink(temp_file)

```

### 3. Allocation

Spatially explicit land use change models are usually driven by non-spatial estimates of land use area for each timestep in the simulation.
While many complex methods have been devised, in lulcc we simply provide a method for linear extrapolation of land use change, which relies on there being at least two observed land use maps:

```{r DemandTest}
# set variable timewindow for testing
timewindow <- c(0,10)

# obtain demand scenario from extrapolated land use change
dmd <- approxExtrapDemand(obs=obs, t=timewindow)
dmd
```

We then use a filter defined as a matrix within the `NeighbRasterStack` function to gather neighbor data from the land use change data.
```{r NeighborModelTest}
w <- matrix(data=1, nrow=3, ncol=3)
nb <- NeighbRasterStack(x=obs[[1]], weights=w,
                        categories=c(1,2,3,4))
histRaster <- obs[[1]]  # This extracts the first layer as a RasterLayer
```

The culmination of the modelling process is to simulate the location of land use change. lulcc provides a routine based on the CLUE-S model (Verburg et al., 2002) and a novel stochastic allocation procedure (with option for using the ordered method). The first step is to combine the various model inputs to ensure they are compatible:

```{r CLUESModelTest}
clues.rules <- matrix(data=1, nrow=4, ncol=4)

clues.parms <- list(jitter.f=0.0002,
                    scale.f=0.000001,
                    max.iter=5000,
                    max.diff=50,
                    ave.diff=50)

clues.model <- CluesModel(obs=obs,
                          ef=ef,
                          models=rf.models,
                          time=timewindow,
                          demand=dmd,
                          hist=histRaster,
                          # mask=dummyMask,
                          neighb=nb,
                          elas=c(0.2,0.2,0.2,0.2),
                          rules=clues.rules,
                          params=clues.parms)

ordered.model <- OrderedModel(obs=obs,
                              ef=ef,
                              models=rf.models,
                              time=timewindow,
                              demand=dmd,
                              order=c(3,2,1,4))
```

Allocate demand to the models
```{r AllocationTest}
clues.model <- allocate(clues.model)
ordered.model <- allocate(ordered.model, stochastic=TRUE)
```

# Plot and Output Rasters
Clue-S Model Test
```{r CluesTest, fig.width=10}
# Assuming 'clues.model' is your CluesModel object
clues_output <- clues.model@output

clues_output_2013 <- ordered.model@output[[1]]
clues_output_2023 <- ordered.model@output[[2]]

# Plotting with rasterVis
levelplot(clues_output, 
          col.regions=colorRampPalette(c("darkgreen", "tan", "red", "blue")),
          # col.regions=colorRampPalette(c("darkgreen", "tan", "red")),   
          main="Future Land Use Categories (CLUE-S)")

num_layers <- nlayers(clues.model@output)
print(num_layers)
```

Ordered Model Test
```{r OrderedTest, fig.width=10}
# Check if ordered.model@output is a list and contains raster objects
if("list" %in% class(ordered.model@output) && all(sapply(ordered.model@output, function(x) inherits(x, "Raster")))) {
  for(i in seq_along(ordered.model@output)) {
    # Attempt to safely modify the raster values
    try({
      current_raster <- ordered.model@output[[i]]
      # Ensure the object is a RasterLayer
      if(inherits(current_raster, "RasterLayer")) {
        # Manually reassign values
        values(current_raster)[values(current_raster) == -1] <- 1
        ordered.model@output[[i]] <- current_raster
      }
    }, silent = TRUE)
  }
} else {
  message("The ordered.model@output does not contain a modifiable list of Raster objects.")
}


# # Plotting with rasterVis
# levelplot(ordered.model@output,
#           col.regions=colorRampPalette(c("darkgreen", "tan", "red", "blue")),
#           main="Land Use Categories (Random Forest ModelOrdered)")

# # Generate individual plots with specific titles
# plot1 <- levelplot(ordered.model@output[[1]], 
#                    col.regions=colorRampPalette(c("darkgreen", "tan", "red", "blue")),
#                    main="2013 Land Cover")
# 
# plot2 <- levelplot(ordered.model@output[[2]], 
#                    col.regions=colorRampPalette(c("darkgreen", "tan", "red", "blue")),
#                    main="2023 Land Cover")
# 
# # Arrange the plots together
# grid.arrange(plot1, plot2, ncol=1)

```


### 4. Validation

An important yet frequently overlooked aspect of land use change modelling is model validation. lulcc provides a recent validation method developed by Pontius et al. (2011), which simultaneously compares a reference (observed) map for time 1, a reference map for time 2 and a simulated map for time 2. The first step in this method is to calculate three dimensional contingency tables:

```{r ThreemapComparison}
# evaluate CLUE-S model output
clues.tabs <- ThreeMapComparison(x=clues.model,
                                   factors=c(1, 2, 4),
                                   timestep=10)

ordered.tabs <- ThreeMapComparison(x=ordered.model,
                                   factors=c(1, 2, 4),
                                   timestep=10)
```

From these tables we can easily extract information about different types of agreement and disagreement as well as compute summary statistics such as the figure of merit:
Agreement Plot
```{r AgreementBudget, echo=TRUE}
clues.agr <- AgreementBudget(x=clues.tabs)
# plot(clues.agr)

ordered.agr <- AgreementBudget(x=ordered.tabs)
# plot(ordered.agr)
```

Export Agreement Plot
```{r AgreementPlotExport}
# Function to create and upload a plot
create_and_upload_plot <- function(plot_code, plot_name) {

  # Ensure the local output directory exists
  if(!dir.exists(file.path(output_folder, outputs))) {
    dir.create(file.path(output_folder, outputs), recursive = TRUE)
  }

  # Create a temporary file path for the plot
  temp_file <- tempfile(fileext = ".png")
  
  # Start PNG device with the temporary file path
  png(temp_file, width = 1600, height = 900)
  
  # Execute the plotting code
  plot_code()
  
  # Close the plotting device
  dev.off()
  
  # Construct the full path for local saving
  local_file_path <- file.path(output_folder, outputs, plot_name)
  
  # Move the plot from the temporary location to the final local path
  file.copy(temp_file, local_file_path, overwrite = TRUE)
  
  # Set the GCS path which includes the folder structure within the bucket
  gcs_path <- file.path("data", outputs, plot_name)
  
  # Upload the PNG file to Google Cloud Storage
  gcs_upload(local_file_path, name = gcs_path)
  
  # Remove the temporary and local file to free up space
  unlink(temp_file)
  unlink(local_file_path)
}

# Example usage:
# Create and upload "Clue-S AgreementBudget.png"
create_and_upload_plot(plot_code = function() plot(clues.agr), plot_name = "Clue-S_AgreementBudget.png")

# Create and upload "Ordered AgreementBudget.png"
create_and_upload_plot(plot_code = function() plot(ordered.agr), plot_name = "Ordered_AgreementBudget.png")

```

```{r FigureOfMerit, echo=TRUE}
# clues.fom <- FigureOfMerit(x=clues.agr)
# plot(clues.fom, from=1, to=2)
# plot(clues.fom, from=1, to=3)
# plot(clues.fom, from=2, to=3)
# 
# ordered.fom <- FigureOfMerit(x=ordered.agr)
# plot(ordered.fom, from=1, to=2)
# plot(ordered.fom, from=1, to=3)
# plot(ordered.fom, from=2, to=3)
```

### 4. Extrapolation
Clue-S Model
<br>
Demand Estimation
```{r DemandExtrapolation}
# set variable timewindow for extrapolating land cover change to 2100
timewindow <- c(0,10,37)

# obtain demand scenario from extrapolated land use change
dmd <- approxExtrapDemand(obs=obs, t=timewindow)
dmd
```

Manually-assign demand (scenario-based modeling)
```{r ManualDemandSpecificaiton}
# # Example demand data for timesteps 0 and 10
# dmd <- data.frame(
#   timestep = c(0, 10),
#   Forest = c(forest_area_at_0, forest_area_at_10),
#   Other = c(other_area_at_0, other_area_at_10),
#   Built = c(built_area_at_0, built_area_at_10),
#   Water = c(water_area_at_0, water_area_at_10)
# )
```

Gather neighbor data from the land use change data.
```{r NeighborData}
w <- matrix(data=1, nrow=3, ncol=3)
nb <- NeighbRasterStack(x=obs[[1]], weights=w,
                        categories=c(1,2,3,4))
histRaster <- obs[[1]]  # This extracts the first layer as a RasterLayer
```

The culmination of the modelling process is to simulate the location of land use change. lulcc provides a routine based on the CLUE-S model (Verburg et al., 2002) and a novel stochastic allocation procedure (with option for using the ordered method). The first step is to combine the various model inputs to ensure they are compatible:

```{r CLUES_Model}
clues.rules <- matrix(data=1, nrow=4, ncol=4)

clues.parms <- list(jitter.f=0.0002,
                    scale.f=0.000001,
                    max.iter=5000,
                    max.diff=50,
                    ave.diff=50)

clues.model <- CluesModel(obs=obs,
                          ef=ef,
                          models=rf.models,
                          time=timewindow,
                          demand=dmd,
                          hist=histRaster,
                          # mask=dummyMask,
                          neighb=nb,
                          elas=c(0.2,0.2,0.2,0.2),
                          rules=clues.rules,
                          params=clues.parms)

clues.model <- allocate(clues.model)
```

# Plot and Output Rasters
Clue-S Model Test
```{r CluesVisualization, fig.width=10}
# Assuming 'clues.model' is your CluesModel object
clues_output <- clues.model@output

# Plotting with rasterVis
levelplot(clues_output, 
          col.regions=colorRampPalette(c("darkgreen", "tan", "red", "blue")), 
          main="Future Land Use Categories (CLUE-S)")

```

# 5. Exporting Rasters 
```{r ExportRasters}
# Function to write and upload a raster
upload_raster <- function(raster_obj, file_name) {
  # Define output folder and results type (assumed to be defined globally or pass as parameters)
  output_folder <- "data"  # Local directory to store files
  crop_res <- "results"    # Subfolder for categorizing outputs

  # Ensure the local output directory exists
  if(!dir.exists(file.path(output_folder, outputs))) {
    dir.create(file.path(output_folder, outputs), recursive = TRUE)
  }

  # Create a temporary file
  temp_file <- tempfile(fileext = ".tif")
  
  # Write the raster to the temporary file
  writeRaster(raster_obj, filename = temp_file, format = "GTiff", overwrite = TRUE)
  
  # Construct the full path for local saving
  local_file_path <- file.path(output_folder, outputs, file_name)
  
  # Move the raster from the temporary location to the final local path
  file.copy(temp_file, local_file_path, overwrite = TRUE)
  
  # Set the GCS path which includes the folder structure within the bucket
  gcs_path <- file.path("data", outputs, file_name)
  
  # Upload the TIFF file to Google Cloud Storage
  gcs_upload(local_file_path, name = gcs_path)
  
  # Remove the temporary and local file to free up space
  unlink(temp_file)
  unlink(local_file_path)
}

# Example usage:
# Extract the second band for 2050 land cover data
lc_2050 <- raster(clues_output, layer=2)
# Export and upload 2050 land cover data
upload_raster(lc_2050, "lc_2050.tif")

# Assume lc_2023_raster is already defined and ready
# Export and upload 2023 land cover data
upload_raster(lc_2023_raster, "lc_2023.tif")



```

