{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "import rioxarray\n",
    "import json\n",
    "import rasterio\n",
    "from rioxarray.merge import merge_arrays\n",
    "from shapely.geometry import Polygon\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to extract the landcover data to a geopandas dataframe\n",
    "def extract_landcover_data(RCP=\"RCP26\", model=\"GFDL\", year= '2050'):\n",
    "    # get the landcover data\n",
    "    data_path = \"D:\\hotspot mapping\\Land_Use_Harmonization_V2_1721\\data\"\n",
    "\n",
    "    file_path = data_path + f\"\\{RCP}_{model}_states.nc4\"\n",
    "    # Load .nc4 file\n",
    "    dataset = xr.open_dataset(file_path)\n",
    "\n",
    "    datetime = f'{year}-01-01 00:00:00'\n",
    "    \n",
    "    # traverse all the variables in the dataset\n",
    "    gdf_list = []\n",
    "    final_gdf = gpd.GeoDataFrame()\n",
    "    for land in dataset.data_vars:\n",
    "        if land==\"crs\":\n",
    "            continue\n",
    "        # print(land)\n",
    "        df = dataset[land].sel(time=datetime).to_dataframe().reset_index()\n",
    "        gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.lon, df.lat)).drop([\"lat\",\"lon\",\"time\"], axis=1)\n",
    "        # print(gdf.head())\n",
    "        # print(final_gdf.head())\n",
    "        if final_gdf.empty:\n",
    "            final_gdf = gdf\n",
    "        else:\n",
    "            final_gdf = gpd.sjoin(final_gdf, gdf, how=\"left\")\n",
    "            # remove the duplicate columns\n",
    "            final_gdf = final_gdf.drop([\"index_right\"], axis=1)\n",
    "    \n",
    "    # df = dataset.sel(time=datetime).to_dataframe()\n",
    "    return final_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_land_cover_gdf(area_gdf, area_polygon=None):\n",
    "    # drop the rows with null 'urban' values\n",
    "    area_gdf = area_gdf.dropna(subset=['urban'])\n",
    "    # change the geometry from point to polygon\n",
    "    area_gdf['geometry'] = area_gdf['geometry'].apply(lambda x: Polygon([[x.x-0.125, x.y-0.125], [x.x-0.125, x.y+0.125], [x.x+0.125, x.y+0.125], [x.x+0.125, x.y-0.125]]))\n",
    "    \n",
    "    # get polygon of costa rica\n",
    "    if(area_polygon==None):\n",
    "        url = 'https://raw.githubusercontent.com/HotspotStoplight/HotspotStoplight/main/CropBoxes/CR_Crop3.geojson'\n",
    "        gdf2 = gpd.read_file(url)\n",
    "\n",
    "        area_polygon = gdf2.geometry[0]\n",
    "    \n",
    "    # get the intersection of the landcover data and the area polygon\n",
    "    area_gdf['intersection'] = area_gdf.intersection(area_polygon)\n",
    "    area_gdf['area'] = area_gdf['intersection'].area\n",
    "    # forest types\n",
    "    forest_types = ['primf','secdf']\n",
    "    \n",
    "    # impute the null values with 0\n",
    "    area_gdf['area'] = area_gdf['area'].fillna(0)\n",
    "    # get the total fraction for each row\n",
    "    area_gdf['forest']=area_gdf.apply(lambda x: sum(x[forest_types]), axis=1)\n",
    "    area_gdf['other types'] = 1-area_gdf['forest']-area_gdf['urban']\n",
    "\n",
    "    return area_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "type",
     "evalue": "name 'process_land_cover_gdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7952\\1010469106.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_landcover_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0marea_gdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_land_cover_gdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'process_land_cover_gdf' is not defined"
     ]
    }
   ],
   "source": [
    "gdf = extract_landcover_data()\n",
    "area_gdf = process_land_cover_gdf(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landcover_demand_from_gdf(area_gdf):\n",
    "    # calculate the demand for each landcover type\n",
    "    land_cover_list = ['forest', 'urban', 'other types']\n",
    "    land_cover_demand = []\n",
    "    for land in land_cover_list:\n",
    "        land_cover_demand.append((area_gdf[land] * area_gdf['area']).sum())\n",
    "    total_area = area_gdf['area'].sum()\n",
    "    land_cover_demand = [x/total_area for x in land_cover_demand]\n",
    "    return land_cover_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_model_demand(RCP=\"RCP26\", model=\"GFDL\", year= '2050',area_polygon=None):\n",
    "    gdf = extract_landcover_data(RCP, model, year)\n",
    "    area_gdf = process_land_cover_gdf(gdf,area_polygon)\n",
    "    land_cover_demand = get_landcover_demand_from_gdf(area_gdf)\n",
    "    print(\"model: \", model, \"demand: \", land_cover_demand)\n",
    "    return land_cover_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_demand(RCP=\"RCP26\", year= '2050',area_polygon=None):\n",
    "    models = ['GFDL', 'IPSL', 'MIROC', 'HADGEM']\n",
    "    model_demands = []\n",
    "    for model in models:\n",
    "        model_demands.append(get_single_model_demand(RCP, model, year,area_polygon))\n",
    "    # get the average demand\n",
    "    avg_demand = np.mean(model_demands, axis=0)\n",
    "    return avg_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_csv(demand_list):\n",
    "    land_cover_demand_dict = dict(zip(['forest', 'urban', 'other types'], demand_list))\n",
    "    # convert the dictionary to a csv file\n",
    "    land_cover_demand_df = pd.DataFrame(land_cover_demand_dict, index=[0])\n",
    "    # add the row key\n",
    "    land_cover_demand_df.to_csv('land_cover_demand.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_demand = get_avg_demand()\n",
    "output_csv(avg_demand)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
