---
output: github_document
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

lulcc provides a framework for spatially explicit land use change modelling in r. The long term goal of lulcc is to  provide a smart and tidy interface to running the standard land use change modelling in 4 steps: raster data prepping, probability surface generation, allocation and validation, in one tidy package.

## Installation

You can install the released version of lulcc from [CRAN](https://CRAN.R-project.org) with:

``` {r}
# install.packages("lulcc")
```

And the development version from [GitHub](https://github.com/) with:

``` {r}
# install.packages("devtools")
# devtools::install_github("simonmoulds/lulcc")
```
## The lulcc workflow
*Adapted from https://www.geosci-model-dev.net/8/3215/2015/*

```{r}
library(lulcc)
library(raster)
library(rasterVis)
library(googleCloudStorageR)
```

```{r}
inputs <- '/Users/oliveratwood/Documents/GitHub/HotspotStoplight/LandCoverChange/data/inputs/cropped/crop4_100m'

outputs <- "/Users/oliveratwood/Documents/GitHub/HotspotStoplight/LandCoverChange/data/outputs/cropped/crop4_100m"
# outputs <- "/Users/oliveratwood/Documents/GitHub/HotspotStoplight/LandCoverChange/data/outputs/cropped/crop5a_30m"
```

### 1. Raster data preparation

Land use change modelling requires a large amount of input data. The most important input is at least one map of observed land use. In lulcc, this data is represented by the `ObsLulcRasterStack` class:

```{r LoadAndPrep}
# List all files in the directory
files <- list.files(path = inputs, full.names = TRUE)

# Filter for .RData files
rdata_files <- files[grepl("\\.RData$", files)]

# Load each .RData file
lapply(rdata_files, load, .GlobalEnv)


# # LandCover
# url <- "https://github.com/HotspotStoplight/LandCoverChange/raw/main/data/inputs/cropped/crop4_90m/LandCover.RData"
# # url <- "https://github.com/HotspotStoplight/LandCoverChange/raw/main/data/inputs/cropped/crop5a_30m/LandCover.RData"
# load(url(url))
# 
# # # Factors
# url <- "https://github.com/HotspotStoplight/LandCoverChange/raw/main/data/inputs/cropped/crop4_90m/Factors.RData"
# # url <- "https://github.com/HotspotStoplight/LandCoverChange/raw/main/data/inputs/cropped/crop5a_30m/Factors.RData"
# load(url(url))

# Check the unique values
for(i in 1:nlayers(LandCover)) {
  print(unique(values(LandCover[[i]])))}

obs <- ObsLulcRasterStack(x=LandCover,
                          pattern="lc",
                          categories=c(1,2,3,4),
                          labels=c('Forest', 'Other', 'Built', 'Water'),
                          t=c(0,10))
```


```{r, fig.width=12, fig.height=6.75}
# Assuming your ObsLulcRasterStack 'obs' is compatible with raster plotting
# Extract layers by time points (assuming two time points for simplicity)
lc_2013_raster <- raster(obs, layer=1)
lc_2023_raster <- raster(obs, layer=2)

# Plot the first time point
plot(lc_2013_raster, main="Land Cover 2013", col=c('darkgreen', 'tan', 'red', 'blue'), breaks=c(0.5, 1.5, 2.5, 3.5, 4.5), legend=FALSE)
legend("topright", legend=c('Forest', 'Other', 'Built', 'Water'), fill=c('darkgreen', 'tan', 'red', 'blue'))

# Plot the second time point
plot(lc_2023_raster, main="Land Cover 2023", col=c('darkgreen', 'tan', 'red', 'blue'), breaks=c(0.5, 1.5, 2.5, 3.5, 4.5), legend=FALSE)
legend("topright", legend=c('Forest', 'Other', 'Built', 'Water'), fill=c('darkgreen', 'tan', 'red', 'blue'))

```

A useful starting point in land use change modelling is to obtain a transition matrix for two observed land use maps to identify the main transitions. This can be achieved with the `crossTabulate` function:

```{r CrossTab, echo=TRUE}
# obtain a transition matrix from land use maps for 1985 and 1991
crossTabulate(obs, times=c(0,10))
```

The next stage is to relate observed land use or observed land use transitions to spatially explicit biophysical or socioeconomic explanatory variables. These are loaded as follows:

```{r PrepVars}
ef <- ExpVarRasterList(x=Factors, pattern="ef")
```

### 2. Probability surface modelling

To fit predictive models we first divide the study region into training and testing partitions. The `partition` function returns a list with cell numbers for each partition:

```{r Partition}
part <- partition(x=obs[[1]],
                  size=0.1, spatial=TRUE)
```

We then extract cell values for the training and testing partitions.

```{r TrainTest}
# extract training data
train.data <- getPredictiveModelInputData(obs=obs,
                                          ef=ef,
                                          cells=part[["train"]],
                                          t=0)

test.data <- getPredictiveModelInputData(obs=obs,
                                         ef=ef,
                                         cells=part[["test"]])
```

Predictive models are represented by the `PredictiveModelList` class. For comparison, we create a `PredictiveModelList` object for each type of predictive model:

```{r Modelling}
# fit models (note that a predictive model is required for each land use category)
# Factors <- stack(pop2010, slope, dist_urban, dist_road, dist_highway)

forms <- list(Forest~ef_01+ef_02+ef_03+ef_04+ef_05,
              Other~ef_01+ef_02+ef_03+ef_04+ef_05,
              Built~ef_01+ef_02+ef_03+ef_04+ef_05,
              Water~ef_01+ef_02+ef_03+ef_04+ef_05)

# generalized linear model models
glm.models <- glmModels(formula=forms,
                        family=binomial,
                        data=train.data,
                        obs=obs)

# recursive partitioning and regression tree models
# rpart.models <- rpartModels(formula=forms,
#                             data=train.data,
#                             obs=obs)

# random forest models (WARNING: takes a long time!)
rf.models <- randomForestModels(formula=forms,
                                data=train.data,
                                obs=obs,
                                na.action=na.omit)

```

We can then use the fitted models to predict over the full data set and produce the probability surfaces for each fitted model:

```{r ProbabilityMaps, echo = TRUE, fig.width=10}
all.data <- as.data.frame(x=ef, obs=obs, cells=part[["all"]])

probmaps <- predict(object=rf.models,
                    newdata=all.data,
                    data.frame=TRUE)
points <- rasterToPoints(obs[[1]], spatial=TRUE)
probmaps <- SpatialPointsDataFrame(points, probmaps)
probmaps <- rasterize(x=probmaps, y=obs[[1]],
                      field=names(probmaps))
rasterVis::levelplot(probmaps)
```
# OUTPUT PROBABILITY RASTERS
```{r}
# Set Working outputs
setwd(outputs)

# Loop through each band
for (i in 1:nlayers(probmaps)) {
  # Extract the single band
  single_band <- raster(probmaps, layer = i)

  # Create a filename from the band's name
  filename <- paste0(names(single_band), ".tif")

  # Write the single band raster to a TIFF file
  writeRaster(single_band, filename, format = "GTiff", overwrite = TRUE)
}

```


Model performance is assessed using the receiver operator characteristic provided by the [ROCR](http://cran.r-project.org/web/packages/ROCR/index.html) package. lulcc includes classes `Prediction` and `Performance` which extend the native ROCR classes to contain multiple `prediction` and `performance` objects. The procedure to obtain these objects and assess performance is as follows:

```{r Performances, echo = TRUE}
#GLM
glm.pred <- PredictionList(models=glm.models,
                           newdata=test.data)
glm.perf <- PerformanceList(pred=glm.pred,
                            measure="rch")
#RPART
# rpart.pred <- PredictionList(models=rpart.models,
#                              newdata=test.data)
# rpart.perf <- PerformanceList(pred=rpart.pred,
#                               measure="rch")

#Random Forest
rf.pred <- PredictionList(models=rf.models,
                          newdata=test.data)
rf.perf <- PerformanceList(pred=rf.pred,
                           measure="rch")
#Plot ROC Curves
plot(list(glm=glm.perf,
          rf=rf.perf))
```
Export ROC Curves
```{r}
# Set Working outputs
setwd(outputs)

# Specify the file path and name, along with desired dimensions
png("ROC_Curves.png", width = 1600, height = 900)

# Your plotting code
plot(list(glm=glm.perf,
          rpart=rpart.perf,
          rf=rf.perf))

# Close the plotting device
dev.off()
```

Another use of ROC analysis is to assess how well the models predict the cells in which gain occurs between two time points. This is only possible if a second observed land use map is available for a subsequent time point. Here we perform this type of analysis for the gain of built between 1985 and 1991. First, we create a data partition in which cells not candidate for gain (cells belonging to built in 1985) are eliminated. We then assess the ability of the various predictive models to predict the gain of built in this partition:

```{r PerformancesTest}
# part <- rasterToPoints (obs[[1]],
#                         fun=function(x) x != 2,
#                         spatial=TRUE)
# test.data<- getPredictiveModelInputData(obs=obs,
#                                         ef=ef,
#                                         cells=part,
#                                         t=6)
# glm.pred <- PredictionList(models=glm.models[[2]],
#                            newdata=test.data)
# glm.perf <- PerformanceList(pred=glm.pred,
#                             measure="rch")
# plot(list(glm=glm.perf))
```

### 3. Allocation

Spatially explicit land use change models are usually driven by non-spatial estimates of land use area for each timestep in the simulation.
While many complex methods have been devised, in lulcc we simply provide a method for linear extrapolation of land use change, which relies on there being at least two observed land use maps:

```{r Demand}
# set variable timewindow for testing
timewindow <- c(0,10)

# obtain demand scenario from extrapolated land use change
dmd <- approxExtrapDemand(obs=obs, tout=timewindow)
dmd
```

We then use a filter defined as a matrix within the `NeighbRasterStack` function to gather neighbor data from the land use change data.
```{r Neigh}
w <- matrix(data=1, nrow=3, ncol=3)
nb <- NeighbRasterStack(x=obs[[1]], weights=w,
                        categories=c(1,2,3,4))
histRaster <- obs[[1]]  # This extracts the first layer as a RasterLayer
```

The culmination of the modelling process is to simulate the location of land use change. lulcc provides a routine based on the CLUE-S model (Verburg et al., 2002) and a novel stochastic allocation procedure (with option for using the ordered method). The first step is to combine the various model inputs to ensure they are compatible:

```{r CLUES}
clues.rules <- matrix(data=1, nrow=4, ncol=4)

clues.parms <- list(jitter.f=0.0002,
                    scale.f=0.000001,
                    max.iter=5000,
                    max.diff=50,
                    ave.diff=50)

clues.model <- CluesModel(obs=obs,
                          ef=ef,
                          models=rf.models,
                          time=timewindow,
                          demand=dmd,
                          hist=histRaster,
                          # mask=dummyMask,
                          neighb=nb,
                          elas=c(0.2,0.2,0.2,0.2),
                          rules=clues.rules,
                          params=clues.parms)

ordered.model <- OrderedModel(obs=obs,
                              ef=ef,
                              models=rf.models,
                              time=timewindow,
                              demand=dmd,
                              order=c(3,2,1,4))
```

Then, finally, we can perform allocation:

```{r Allocation}
clues.model <- allocate(clues.model)
ordered.model <- allocate(ordered.model, stochastic=TRUE)
```

```{r}
summary(obs)
summary(ef)
summary(dmd)
summary(ordered.model)
```

# Plot and Output Rasters
Clue-S Model Test
```{r, fig.width=10}
# Assuming 'clues.model' is your CluesModel object
clues_output <- clues.model@output

# Plotting with rasterVis
levelplot(clues_output, 
          col.regions=colorRampPalette(c("darkgreen", "tan", "red", "blue")), 
          main="Future Land Use Categories (CLUE-S)")

```
Ordered Model Test
```{r}
# # Step 1: Extract the raster data from the S4 object
# # Assuming the slot containing the raster data is named 'rasters'
# raster_data <- ordered.model@output
# 
# # Step 2: Reclassify the raster data
# # Create a matrix specifying the reclassification rules
# # Here, rows are of the form c(from, to, becomes), and you can add more rows as needed
# reclass_matrix <- matrix(c(-1, -1, 1), ncol = 3, byrow = TRUE)
# 
# # Use the reclassify function
# reclassified_raster <- reclassify(raster_data, reclass_matrix)
# 
# # Step 3: Replace the original raster data in the S4 object with the reclassified version
# ordered.model@output <- reclassified_raster
# 
# # Plotting with rasterVis
# levelplot(ordered.model@output,
#           col.regions=colorRampPalette(c("darkgreen", "tan", "red", "blue")),
#           main="Future Land Use Categories (Ordered)")
```


### 4. Validation

An important yet frequently overlooked aspect of land use change modelling is model validation. lulcc provides a recent validation method developed by Pontius et al. (2011), which simultaneously compares a reference (observed) map for time 1, a reference map for time 2 and a simulated map for time 2. The first step in this method is to calculate three dimensional contingency tables:

```{r Threemap}
# evaluate CLUE-S model output
clues.tabs <- ThreeMapComparison(x=clues.model,
                                   factors=2^(1:8),
                                   timestep=10)
```

From these tables we can easily extract information about different types of agreement and disagreement as well as compute summary statistics such as the figure of merit:
Agreement Plot
```{r AgreementBudget, echo=TRUE}
clues.agr <- AgreementBudget(x=clues.tabs)
plot(clues.agr)
```

Export Agreement Plot
```{r}
# Set Working outputs
setwd(outputs)

# Specify the file path and name, along with desired dimensions
png("Clue-S_AgreementBudget.png", width = 1600, height = 900)

# Your plotting code
plot(clues.agr)

# Close the plotting device
dev.off()
```

```{r FigureOfMerit, echo=TRUE}
clues.fom <- FigureOfMerit(x=clues.agr)
plot(clues.fom, from=1, to=2)
plot(clues.fom, from=1, to=3)
plot(clues.fom, from=2, to=3)
```

### 4. Extrapolation
Clue-S Model
<br>
Demand Estimation
```{r Demand}
# set variable timewindow for extrapolating land cover change to 2050
timewindow <- c(10,37)

# obtain demand scenario from extrapolated land use change
dmd <- approxExtrapDemand(obs=obs, tout=timewindow)
dmd
```

Manually-assign demand (scenario-based modeling)
```{r Demand alternate}
# # Example demand data for timesteps 0 and 10
# dmd <- data.frame(
#   timestep = c(0, 10),
#   Forest = c(forest_area_at_0, forest_area_at_10),
#   Other = c(other_area_at_0, other_area_at_10),
#   Built = c(built_area_at_0, built_area_at_10),
#   Water = c(water_area_at_0, water_area_at_10)
# )
```

Gather neighbor data from the land use change data.
```{r Neigh}
w <- matrix(data=1, nrow=3, ncol=3)
nb <- NeighbRasterStack(x=obs[[1]], weights=w,
                        categories=c(1,2,3,4))
histRaster <- obs[[1]]  # This extracts the first layer as a RasterLayer
```

The culmination of the modelling process is to simulate the location of land use change. lulcc provides a routine based on the CLUE-S model (Verburg et al., 2002) and a novel stochastic allocation procedure (with option for using the ordered method). The first step is to combine the various model inputs to ensure they are compatible:

```{r CLUES}
clues.rules <- matrix(data=1, nrow=4, ncol=4)

clues.parms <- list(jitter.f=0.0002,
                    scale.f=0.000001,
                    max.iter=5000,
                    max.diff=50,
                    ave.diff=50)

clues.model <- CluesModel(obs=obs,
                          ef=ef,
                          models=rf.models,
                          time=timewindow,
                          demand=dmd,
                          hist=histRaster,
                          # mask=dummyMask,
                          neighb=nb,
                          elas=c(0.2,0.2,0.2,0.2),
                          rules=clues.rules,
                          params=clues.parms)

```

Then, finally, we can perform allocation:

```{r Allocation}
clues.model <- allocate(clues.model)
```

```{r}
summary(obs)
summary(ef)
summary(dmd)
summary(ordered.model)
```
# Plot and Output Rasters
Clue-S Model Test
```{r, fig.width=10}
# Assuming 'clues.model' is your CluesModel object
clues_output <- clues.model@output

# Plotting with rasterVis
levelplot(clues_output, 
          col.regions=colorRampPalette(c("darkgreen", "tan", "red", "blue")), 
          main="Future Land Use Categories (CLUE-S)")

```

# 5. Exporting Rasters 
```{r}
# Set Working outputs
setwd(outputs)

# Extract the second band
lc_2050 <- raster(clues_output, layer=2)

# Export 2050 land cover data
writeRaster(lc_2050, filename="lc_2050.tif", format="GTiff", overwrite=TRUE)

# Export 2023 land cover data
writeRaster(lc_2023_raster, filename="lc_2023.tif", format="GTiff", overwrite=TRUE)

```

```{r}
plot(lc_2023_raster)
plot(lc_2050)
```

